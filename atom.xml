<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>petermao</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.petermao.com/"/>
  <updated>2017-02-14T02:15:23.000Z</updated>
  <id>http://www.petermao.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>blog从wordpress迁移到github pages&amp;hexo</title>
    <link href="http://www.petermao.com/blog/hello-github-pages-hexo/"/>
    <id>http://www.petermao.com/blog/hello-github-pages-hexo/</id>
    <published>2017-01-16T09:28:02.000Z</published>
    <updated>2017-02-14T02:15:23.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="写在开头"><a href="#写在开头" class="headerlink" title="写在开头"></a>写在开头</h2><p>将博客从wordpress系统迁移到github pages+hexo了。</p>
<p>相比于wordpress之类的自己买主机建站，对于我个人来讲，采用github+hexo类的静态化方案有如下几个好处：<br>a) 免费，不限流量<br>b) git版本管理，方便追查修改记录<br>c) 把精力用来写文章(像ci代码一样方便)，不用再做网管了<br>d) 学习下markdown之类的写作语法<br>e) 了解下无后端的前端解决方案<br><a id="more"></a></p>
<p>缺点：<br>a) 折腾。除了markdown语法，各种各样的动态功能往往需要借助外部服务。不过这也是优点。刚好可以熟悉下业内对应的解决方案。<br>b) 静态网页。动态功能需要借助外部服务。<br>c) 需要遍历生成。多一步静态化生成的步骤。网站越大，生成时间也越长。</p>
<p>严格来讲，对于一般的博客，blog数量有限，c不是问题。a与b换个角度也是优点。</p>
<h2 id="实践之路"><a href="#实践之路" class="headerlink" title="实践之路"></a>实践之路</h2><h3 id="入门学习"><a href="#入门学习" class="headerlink" title="入门学习"></a>入门学习</h3><p>参考1)。一开始用的Jekyll。后来迁移到了hexo。<br>githubpages+hexo迁移。参考2)。相比于Jekyll，hexo似乎更简单。</p>
<h3 id="hexo日常使用命令"><a href="#hexo日常使用命令" class="headerlink" title="hexo日常使用命令"></a>hexo日常使用命令</h3><h3 id="url格式"><a href="#url格式" class="headerlink" title="url格式"></a>url格式</h3><p>hexo的默认格式如下：<br><figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">permalink: :year/:month/:day/:title/</div></pre></td></tr></table></figure></p>
<p>按照我以前wordpress的格式进行了调整：<br><figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">permalink: :category/:title/</div></pre></td></tr></table></figure></p>
<h3 id="文章阅读数统计"><a href="#文章阅读数统计" class="headerlink" title="文章阅读数统计"></a>文章阅读数统计</h3><p>参考3)。存储用了leanloud。需要先注册。<br>如果用的next主题，很简单。在leancloud注册后，将_config.xml中的开关打开(搜索leancloud)即可。<br>如果其他主题，需要参考3)所示的链接加入脚本代码。</p>
<h3 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h3><p>markdown的图片引入语法为:”![title](<a href="http://a.com/123.jpeg)&quot;。" target="_blank" rel="external">http://a.com/123.jpeg)&quot;。</a><br>图片加速。参考4)。存储用的七牛云。可以用我的这个<a href="https://portal.qiniu.com/signup?code=3law7drkgerf6" title="七牛邀请链接" target="_blank" rel="external">七牛邀请链接</a>注册。注册后直接引用其生成的链接地址即可。批量工具可以用<a href="https://github.com/qiniu/qshell/blob/master/README.md" target="_blank" rel="external">qshell</a>。简单用法如下。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">$ qshell account ak sk</div><div class="line">$ qshell qupload qshell.config</div><div class="line">$ cat qshell.config</div><div class="line">&#123;</div><div class="line">   <span class="string">"src_dir"</span>            :   <span class="string">"source/cdn"</span>,</div><div class="line">   <span class="string">"bucket"</span>             :   <span class="string">"blog"</span>,</div><div class="line">   <span class="string">"rescan_local"</span>       :   <span class="literal">true</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>先设置ak/sk，然后用quload批量上传。其中src_dir为本地目录， bucket为qiniu上的bucket。</p>
<h3 id="wordpress迁移"><a href="#wordpress迁移" class="headerlink" title="wordpress迁移"></a>wordpress迁移</h3><p>如果顺利的话，似乎几个步骤就搞定了。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ npm install hexo-migrator-wordpress --save</div><div class="line">$ --&gt; WordPress 仪表盘中导出数据(“Tools” → “Export” → “WordPress”)</div><div class="line">$ hexo migrate wordpress &lt;<span class="built_in">source</span>&gt;</div></pre></td></tr></table></figure></p>
<p>非常遗憾。我的blog几乎有大半导不成功。只能手工搞了。而且原来的blog停掉了，只能先手工搭建一个本地的wordpress人工review了。<br>另外像评论、阅读数等等统计也就没有了，只能人工迁移了。</p>
<h3 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h3><p>重点了解下其搜索解决方案。<br>local search:<br>原理是通过hexo-generator-search插件在本地生成一个文件，搜索的时候检索这个文件。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">$ npm install hexo-generator-search --save</div><div class="line">$ npm install hexo-generator-searchdb --save</div><div class="line">$ vim themes/next/_config.yml</div><div class="line">search:</div><div class="line">  path: search.xml</div><div class="line">  field: post</div><div class="line">  format: html</div><div class="line">  <span class="built_in">limit</span>: 10000</div></pre></td></tr></table></figure></p>
<p>algolia: 先注册(非常简单，New Index即可)，然后按如下方式修改本地配置。<br>version为5.1.0，基本只需要简单改下配置即可，但还是有个bug导致被坑了良久。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">$ npm install hexo-algolia --save</div><div class="line">$ vim _config.yml</div><div class="line">algolia:</div><div class="line">  applicationID: <span class="string">'yours'</span></div><div class="line">  apiKey: <span class="string">'yours'</span></div><div class="line">  adminApiKey: <span class="string">'yours'</span></div><div class="line">  indexName: <span class="string">'blog'</span></div><div class="line">  chunkSiz: 5000</div><div class="line"></div><div class="line">$ vim themes/next/_config.yml </div><div class="line">algolia_search:</div><div class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></div><div class="line">  hits:</div><div class="line">    per_page: 10</div><div class="line">  labels:</div><div class="line">    input_placeholder: 输入关键词</div><div class="line">    hits_empty: <span class="string">"没有找到与 <span class="variable">$&#123;query&#125;</span> 相关的内容"</span></div><div class="line">    hits_stats: <span class="string">"<span class="variable">$&#123;hits&#125;</span>条相关记录，共耗时 <span class="variable">$&#123;time&#125;</span> ms"</span></div><div class="line"></div><div class="line">$ vim themes/next/layout/_partials/header.swig (note:我这版本已经有了, 不需要改)</div><div class="line">          &#123;% elseif config.search || theme.algolia_search.enable %&#125;</div><div class="line">            &lt;a href=<span class="string">"javascript:;"</span> class=<span class="string">"popup-trigger"</span>&gt;</div><div class="line"></div><div class="line">$ vim node_modules/hexo-algolia/lib/command.js</div><div class="line">	  var storedPost = _.pick(data, [<span class="string">'title'</span>, <span class="string">'date'</span>, <span class="string">'slug'</span>, <span class="string">'content'</span>, <span class="string">'path'</span>, <span class="string">'excerpt'</span>, <span class="string">'permalink'</span>]);</div><div class="line">$ hexo algolia</div></pre></td></tr></table></figure></p>
<p><img src="http://olan5qt5p.bkt.clouddn.com/algolia.png" alt="效果如下"><br>Swiftype、 微搜索</p>
<h3 id="打赏"><a href="#打赏" class="headerlink" title="打赏"></a>打赏</h3><p>现在支付宝与微信支付都通过扫码就能实现支付，所以原理就是将你的支付账号用图片加载进来。<br>next现在已经集成了该功能。<br>但需要自行打开相关开关。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ ls themes/next/layout/_macro/reward.swig</div><div class="line">$ tail -n 3 themes/next/_config.yml</div><div class="line">reward_comment: Enjoy it ? Donate me !  欣赏此文？求鼓励，求支持！</div><div class="line">alipay: http://static.ixirong.com/pic/donate/alipay1.webp</div><div class="line">wechatpay: http://static.ixirong.com/pic/donate/wechat.png</div></pre></td></tr></table></figure></p>
<h3 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h3><p>整理wordpres的blog时的一大发现就是草稿里累计了好多，需要加把劲完善完善正式发布出来。<br>```</p>
<p><img src="http://olan5qt5p.bkt.clouddn.com/shaoyang.jpeg" alt="邵阳崀山"></p>
<h2 id="致谢与参考"><a href="#致谢与参考" class="headerlink" title="致谢与参考"></a>致谢与参考</h2><p>1 <a href="http://www.ruanyifeng.com/blog/2012/08/blogging_with_jekyll.html" target="_blank" rel="external">搭建一个免费的，无限流量的Blog—-github Pages和Jekyll入门</a></p>
<p>2 <a href="http://www.ezlippi.com//blog/2016/02/jekyll-to-hexo.html" target="_blank" rel="external">Jekyll迁移到Hexo搭建个人博客</a></p>
<p>3 <a href="http://huangnx.com/2016/03/22/BlogNextReadCount/" target="_blank" rel="external">Hexo Next主题添加文章阅读量统计功能</a></p>
<p>4 图片存储<br><a href="http://blog.shiqichan.com/use-qiniu-store-image-for-hexo/" target="_blank" rel="external">使用七牛为Hexo存储图片</a><br><a href="https://github.com/qiniu/qshell/blob/master/README.md" target="_blank" rel="external">qshell</a></p>
<p>5 搜索<br><a href="http://blog.doublez.cc/hexo-next添加algolia搜索.html" target="_blank" rel="external">hexo+next添加algolia搜索</a><br><a href="https://github.com/iissnan/hexo-theme-next/issues/1084" target="_blank" rel="external">next algolia bug</a></p>
<p>5 <a href="http://www.ixirong.com/2015/05/24/hexo-blog-donate/" target="_blank" rel="external">next打赏功能</a></p>
<p>6 <a href="http://theme-next.iissnan.com/third-party-services.html" target="_blank" rel="external">next中文帮助文档</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;写在开头&quot;&gt;&lt;a href=&quot;#写在开头&quot; class=&quot;headerlink&quot; title=&quot;写在开头&quot;&gt;&lt;/a&gt;写在开头&lt;/h2&gt;&lt;p&gt;将博客从wordpress系统迁移到github pages+hexo了。&lt;/p&gt;
&lt;p&gt;相比于wordpress之类的自己买主机建站，对于我个人来讲，采用github+hexo类的静态化方案有如下几个好处：&lt;br&gt;a) 免费，不限流量&lt;br&gt;b) git版本管理，方便追查修改记录&lt;br&gt;c) 把精力用来写文章(像ci代码一样方便)，不用再做网管了&lt;br&gt;d) 学习下markdown之类的写作语法&lt;br&gt;e) 了解下无后端的前端解决方案&lt;br&gt;
    
    </summary>
    
      <category term="blog" scheme="http://www.petermao.com/categories/blog/"/>
    
    
      <category term="blog" scheme="http://www.petermao.com/tags/blog/"/>
    
      <category term="hexo" scheme="http://www.petermao.com/tags/hexo/"/>
    
      <category term="github pages" scheme="http://www.petermao.com/tags/github-pages/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://www.petermao.com/blog/hello-world/"/>
    <id>http://www.petermao.com/blog/hello-world/</id>
    <published>2016-01-16T09:28:02.000Z</published>
    <updated>2017-02-13T06:20:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
    
    </summary>
    
      <category term="blog" scheme="http://www.petermao.com/categories/blog/"/>
    
    
  </entry>
  
  <entry>
    <title>note-</title>
    <link href="http://www.petermao.com/%E6%9C%AA%E5%88%86%E7%B1%BB/note/"/>
    <id>http://www.petermao.com/未分类/note/</id>
    <published>2013-10-09T19:28:16.000Z</published>
    <updated>2017-02-14T02:02:51.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="未分类" scheme="http://www.petermao.com/categories/%E6%9C%AA%E5%88%86%E7%B1%BB/"/>
    
    
  </entry>
  
  <entry>
    <title>leveldb注释2--整体介绍</title>
    <link href="http://www.petermao.com/%E6%9C%AA%E5%88%86%E7%B1%BB/leveldb-note-2-overall-introduction/"/>
    <id>http://www.petermao.com/未分类/leveldb-note-2-overall-introduction/</id>
    <published>2013-10-09T19:24:51.000Z</published>
    <updated>2017-02-14T02:02:51.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="未分类" scheme="http://www.petermao.com/categories/%E6%9C%AA%E5%88%86%E7%B1%BB/"/>
    
    
  </entry>
  
  <entry>
    <title>使用v8识别js重定向</title>
    <link href="http://www.petermao.com/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/v8-js-redirect/"/>
    <id>http://www.petermao.com/搜索引擎/v8-js-redirect/</id>
    <published>2013-06-09T01:11:36.000Z</published>
    <updated>2017-02-14T02:02:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>一 重定向<br>爬虫抓取的过程中，遇到重定向时需要识别出重定向后的url。<br>总结下，主要有如下3类重定向：<br>1   http协议的3XX<br>301  永久移动<br>302  临时<br>305  必须通过指定定代理才能访问相应资源<br>307  临时<a id="more"></a></p>
<p>比如 访问<a href="http://www.meilishuo.com/，响应如下" target="_blank" rel="external">http://www.meilishuo.com/，响应如下</a></p>
<pre>
HTTP/1.1 301 Moved Permanently
Server: mls/1.1
Date: Mon, 01 Jul 2013 07:19:15 GMT
Transfer-Encoding: chunked
Connection: keep-alive
Location: /welcome
Cache-Control: no-cache,must-revalidate,no-store
Pragma: no-cache
</pre>

<p>2   html的meta字段<br>meta字段的refresh属性</p>
<pre>
<html>
<meta http-equiv="refresh" content="1; url=http://www.petermao.com">
<body>
</body></html>
</pre>

<p>3   js重定向<br>有好几种，后面总结下，这里给个简单例子：</p>
<pre>
<html><body>
<script type="text/javascript">window.open("http://www.petermao.com")
</script>
</body></html>
</pre>

<p>解决方案：<br>第一种在获得http首部后，根据状态码，就可以判断是否重定向，再根据location属性来获取重定后的url。</p>
<p>第二种已经获得了网页内容。一般是是通过正则匹配出meta，refresh以及content属性，再获取重定向后的url。当然也可以进行dom解析，正确性会好点，但可能会存在性能问题，个人感觉没有这个必要。正则匹配即可。</p>
<p>第三种是难点。我们先来看看js重定向有哪些表现形式。</p>
<p>二   JS重定向分类<br>主要有如下几类，这里得到了朋友@秋声落叶的帮助，欢迎其他朋友补充。<br>1   window：<br>window.open(url)</p>
<p>2   location属性：</p>
<pre>
location=url;
location.href=url;
window.location=url;
document.location=url;
window.location.href=url;
window.location.replace(url)
window.location.assign(url)
location.replace(url);
location.assign(url);
self.location=url;
top.location=url;
</pre>

<p>3   navigate方法：</p>
<pre>
window.navigate(url)
top.navigate(url);
</pre>

<p>4   document+meta字段</p>
<pre>
document.write('<meta http-equiv="refresh" content="0;url=http://www.petermao.com">');
document.writeIn('<meta http-equiv="refresh" content="0;url=http://www.petermao.com">');
document.close();
</pre>

<p>三   JS重定向识别的1个思路<br>1   问题<br>要识别前面的重定向，通过正则可能不现实，比如前面的JS可以封装在函数里，通过变量来传递重定向后的url。比如前面的location的变种：</p>
<pre>
<html>
<head>
<script type="text/javascript">
function AutoRedirect(seconds,redirectUrl){
setTimeout("Redirect('"+redirectUrl+"')",seconds);}
function Redirect(redirectUrl){
location.href=redirectUrl;
}
</script>
</head>
<body>
<script type="text/javascript">AutoRedirect(2, 'http://www.petermao.com');
</script></body></html>
</pre>

<p>此时要获得这些JS，只能通过完整的解析了，基于DOM树可以完整的获取这些JS。将script当作html的一个标签即可。<br>在完整获得这些JS后，怎么知道其实际表示什么内容了？这个就需要JS运行环境了。可以考虑开源的V8与SpiderMonkey了。（本文只考虑V8）。</p>
<p>2  使用V8的问题<br>不过这里有个问题，对于在浏览器中运行的html网页，浏览器会提供1个叫做window的全局对象，像location、top等对象，以及settimeout等函数就是window的子属性/方法，而这个window的实现被封装在BOM模型（浏览器对象模型）中，该模型不像DOM、JS那样有统一的标准。V8只提供JS运行环境，像window等对象是由浏览器内核提供的，比如webkit中有BOM的实现。之前曾短暂研究过webkit，不过这货太过复杂，还未入门，抽取其中的库来解析与运行网页，不知道是否可行，有研究的朋友可以一起讨论下。前面那些抽取出来的JS，如果直接交给V8来运行，会出现undefined的错误，也就是window、location、settimeout等在V8中并没有定义。</p>
<p>3   最后<br>在只有V8的情况下，如何运行网页中的JS了？那就需要mock了。</p>
<p>V8中表示JS运行环境的是Context对象，我们可以一开始在Context中初始化window等全局对象。然后轮流运行解析出来的JS脚本，最后通过location属性来获取重定向后的url。</p>
<p>最后给出部分初始化mocker代码如下，完整的需要mock前面给出的JS重定向的各种变形。实际mock可以参考Node.js，该货基于V8，提供了一些有用函数的实现，也有利于了解V8的特性。</p>
<p>至于V8的使用，还是翻翻官方文档吧，这里就不说了。</p>
<p>类似的，对于有些JSON数据，或者AJAX的抓取，应该也可以考虑类似的思路。欢迎大家讨论。</p>
<pre>
window = {}; 
location = {}; 
window.location = {}; 
location.href = {}; 
window.location.href = {}; 
top={};
parent={};

location.assign = function (url) {
  window.location.href = url;
}

location.replace = function (url) {
  window.location.href = url;
}

window.location.assign = location.assign;
window.location.replace = location.replace;
---
</pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一 重定向&lt;br&gt;爬虫抓取的过程中，遇到重定向时需要识别出重定向后的url。&lt;br&gt;总结下，主要有如下3类重定向：&lt;br&gt;1   http协议的3XX&lt;br&gt;301  永久移动&lt;br&gt;302  临时&lt;br&gt;305  必须通过指定定代理才能访问相应资源&lt;br&gt;307  临时
    
    </summary>
    
      <category term="搜索引擎" scheme="http://www.petermao.com/categories/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"/>
    
    
      <category term="js重定向" scheme="http://www.petermao.com/tags/js%E9%87%8D%E5%AE%9A%E5%90%91/"/>
    
      <category term="v8" scheme="http://www.petermao.com/tags/v8/"/>
    
      <category term="重定向识别" scheme="http://www.petermao.com/tags/%E9%87%8D%E5%AE%9A%E5%90%91%E8%AF%86%E5%88%AB/"/>
    
  </entry>
  
  <entry>
    <title>基于sitemap的链接收集</title>
    <link href="http://www.petermao.com/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/sitemap/"/>
    <id>http://www.petermao.com/搜索引擎/sitemap/</id>
    <published>2013-05-02T01:56:02.000Z</published>
    <updated>2017-02-14T02:02:51.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>0 sitemap基础</strong></p>
<p>sitemap反映了一个网站网页的整体结构示意图。通过该网页，站长会将需要被抓取的页面全部列出来。<br>sitemap允许级联。按照[1]，sitemap允许三种格式：txt、xml、索引格式。<br>但实际上，大量网站使用普通的html网页作为sitemap链接，因此html网页也需要考虑。<a id="more"></a></p>
<p><strong>1 sitemap的用途</strong><br>sitemap将网站需要被抓取的页面全部列出来，因此该页面一般在站长更新网站内容后更新，可以较好的反映网站内容的实时变化，方便了爬虫的实时抓取。</p>
<p>但另一方面，sitemap是站长主动向大的搜索引擎提交的，因此这些sitemap页面的具体地址并不固定，理论上是可以是任何形式的链接。那么我们如何找到这些链接了？</p>
<p><strong>2 寻找网站的sitemap链接</strong><br>对sitemap地址进行简单的分析后，个人认为主要可以从以下几个方面来收集sitemap链接：<br>a Robots中的sitemap指令<br>Robots.txt中通过sitemap指令来指示sitemap链接的地址，因此我们可以通过对网站的Robots.txt进行解析得到。<br>eg：<a href="http://zhanghanyang.lofter.com/robots.txt" target="_blank" rel="external">http://zhanghanyang.lofter.com/robots.txt</a></p>
<p>b 首页锚文本发现<br>如果首页存在指向sitemap页面的链接的话，一般其锚文本为如下几种：<br>站点地图<br>网站地图<br>网站导航<br>所以这一步可以通过对host首页进行解析得到。<br>eg：<a href="http://redicecn.com/中的网站地图。" target="_blank" rel="external">http://redicecn.com/中的网站地图。</a></p>
<p>c 固定地址尝试<br>sitemap页面通常放在一些固定的地址，比如<a href="http://www.williamlong.info/的sitemap页面就是http://www.williamlong.info/sitemap.asp" target="_blank" rel="external">http://www.williamlong.info/的sitemap页面就是http://www.williamlong.info/sitemap.asp</a>.</p>
<p>观察了下，这些链接是常用的sitemap链接：<br>/sitemap.xml<br>/sitemap.txt<br>/sitemap.html<br>/sitemap.htm<br>/sitemap.php<br>/sitemap.asp<br>/sitemap.jsp<br>/sitemap_baidu.xml<br>/sitemap</p>
<p>另外，对于个人博客来将，通常会有专门的插件来生成sitemap地址，不同的插件生成的默认地址一般不同。比如对DedeCms建站系统，默认路径是/data/sitemap.html。<br>我们可以进一步调研下常用的sitemap自动生成插件，查看下他们的默认路径。</p>
<p>d 人工注入<br>这个必须可以嘛。</p>
<p><strong>3 基于sitemap的链接收集</strong><br>要注意，我们的目的是搜集网站的新链接，而收集sitemap链接只是为了更好的发现这些链接。</p>
<p>因此对于这样1个系统，应该主要由两个子系统组成，一个是sitemap本身的链接发现，另一个就是基于sitemap链接来收集网站的新链接。<br>sitemap本身的链接发现在上个部分已经进行了汇总，为了简便与可扩展，这应该作为1个独立的子系统。</p>
<p>3.1 sitemap本身的链接发现<br>a 输入：一批domain</p>
<blockquote>
<p>生成该domain的robots链接、首页链接并抓取<br>解析Robots页中的sitemap指令执行的链接，首页中锚文本为网站地图、站点题图等链接<br>输出上述链接集合作为S1</p>
</blockquote>
<p>S1 + 人工注入的sitemap链接作为集合S2 + 猜测可能的sitemap地址&lt;猜测的方法见上一节&gt;作为集合S3<br>就是Sitemap链接的种子，将这批数据注入到第二个子系统。</p>
<p>补充说明：在第一轮链接发现后，不需要频繁的进行新sitemap链接发现，只需要人工注入几个未发现的domain的sitemap地址即可。</p>
<p>3.2 基于sitemap链接来收集新链接<br>a 数据的存储：<br>我们怎么来存储这些sitemap链接了？要记得的一个要点是存储这些sitemap链接是为了之后调度，再更好的发现新增的网页内容链接。<br>之前我曾考虑过按host来设计这个子系统，因为一般来说，1个网站我们只需要考虑1个有效的sitemap地址。<br>但经过实践，这样会很复杂，也不便于扩展。按照sitemap最标准的格式，是允许链式指向的，也就是sitemap链接里也可以包含sitemap链接，这会导致存储这些包含关系很复杂；另一方面，考虑到可以将该系统扩展到其他类似系统，按host或者domain来设计不够灵活。因此最好还是一个单独的sitemap链接作为1个单独的key，其他相关属性作为value。</p>
<p>数据的重复性<br>一开始按domain来设计还有一个考虑的原因，就是一个网站通常会提供多个sitemap链接，这些sitemap链接包含的内容应该是等价的。按照我们第一个子系统的方案，1个domain最多有10个左右的可能sitemap链接，会导致10倍左右的额外存储开销。</p>
<p>但最后考虑到系统复杂性、容错与可扩展性，还是允许这些的冗余存在。现实的情况是，我们很难保证1个网站今天使用这个sitemap链接，难保1个月之后不使用其他的sitemap链接，因此使用唯一的sitemap链接是不现实的。另一方面，因为现实中大部分网站只有1~2个sitemap链接，再加上合理的调度方案，这不会导致系统其他组件的过多开销。由于sitemap链接是针对domain级别的，整个存储总量也并不大。</p>
<p>b  调度<br>只要能不断的发现新的链接即可。调度的频率可以根据实际资源&lt;比如爬虫&gt;分配。</p>
<p>c 抓取<br>由于对同一个domain最多只有10个左右的链接，因此对网站不存在较大压力，只要网络带宽足够，可以很快的抓完。</p>
<p>d 解析<br>根据前面的描述，sitemap链接有几种可能的表现形式（txt、html、xml），我们需要对这些一一解析。两个子系统可以共用1个解析模块。</p>
<p>e 垃圾页<br>可能会存在一些spam，反复修改sitemap中的链接。这个需要其他模块反馈。<br>比如对于这种sitemap链接<a href="http://gzfriendly.com/sitemap.xml，里面包含了大量不属于该domain的链接，解析时可直接过滤掉。" target="_blank" rel="external">http://gzfriendly.com/sitemap.xml，里面包含了大量不属于该domain的链接，解析时可直接过滤掉。</a></p>
<p>f 反馈<br>抓取成功率、抓取的性能；贡献的好链接数等。</p>
<p><strong>4 系统的可扩展性</strong><br>类似的，我们可以将该系统扩展到类似于网站主动提供内容索引页的系统，实时且方便。实时爬虫通常需要这些变化快的链接，相同点都是提取出新产生的url链接，计算合理的更新频率并进行调度。比如RSS页、hub页的收集。</p>
<p><strong>5 致谢</strong><br>感谢<a href="http://redicecn.com" target="_blank" rel="external">@redice</a>的帮助，在sitemap的链接发现过程中，提供了诸多帮助。</p>
<p><strong>附：参考</strong><br>[1] 百度sitemap文档<br><a href="http://zhanzhang.baidu.com/wiki/93" target="_blank" rel="external">http://zhanzhang.baidu.com/wiki/93</a></p>
<p>[2] google sitemap文档<br><a href="https://support.google.com/webmasters/topic/8476?hl=en" target="_blank" rel="external">https://support.google.com/webmasters/topic/8476?hl=en</a></p>
<p>[3] Google Sitemaps使用指南<br><a href="http://www.williamlong.info/archives/327.html" target="_blank" rel="external">http://www.williamlong.info/archives/327.html</a></p>
<p>[4] robots中的sitemap指令<br><a href="http://en.wikipedia.org/wiki/Robots.txt#Sitemap" target="_blank" rel="external">http://en.wikipedia.org/wiki/Robots.txt#Sitemap</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;0 sitemap基础&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;sitemap反映了一个网站网页的整体结构示意图。通过该网页，站长会将需要被抓取的页面全部列出来。&lt;br&gt;sitemap允许级联。按照[1]，sitemap允许三种格式：txt、xml、索引格式。&lt;br&gt;但实际上，大量网站使用普通的html网页作为sitemap链接，因此html网页也需要考虑。
    
    </summary>
    
      <category term="搜索引擎" scheme="http://www.petermao.com/categories/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"/>
    
    
      <category term="sitemap" scheme="http://www.petermao.com/tags/sitemap/"/>
    
      <category term="网站地图" scheme="http://www.petermao.com/tags/%E7%BD%91%E7%AB%99%E5%9C%B0%E5%9B%BE/"/>
    
      <category term="链接收集" scheme="http://www.petermao.com/tags/%E9%93%BE%E6%8E%A5%E6%94%B6%E9%9B%86/"/>
    
  </entry>
  
  <entry>
    <title>网页spam相关论文了解</title>
    <link href="http://www.petermao.com/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/spam/"/>
    <id>http://www.petermao.com/搜索引擎/spam/</id>
    <published>2013-04-13T18:08:04.000Z</published>
    <updated>2017-02-14T02:02:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近对网页spam有兴趣，找了些论文看看，部分还没看完，做个小结吧，后续再慢慢看，慢慢补充了。<br>主要内容都是参考里的论文里的。</p>
<p>1 spam基础<br>那些误导搜索引擎排名的行为或者从搜索引擎中获得不应有的利益的行为都可以称为spam，具体是否为spam取决于搜索引擎的判断标准。</p>
<p>简单来说，那些搜索引擎明文允许进行的或者即使搜索引擎不存在但仍存在的“优化”行为可以认为不是spam。比如一些针对特定client、终端的优化行为不能认为是spam。再比如垃圾网站里贴出的链接，这些链接不应该作为spam，因为这些链接的存在超出了链接目的地的owner的控制，惩罚的应该是垃圾网站本身而不是它指向的链接。<a id="more"></a><br>Anything that would still be done if search engines did not exist, or anything that a search engine has given written permission to do.[2]</p>
<p>英文spam据估计在15%左右，也可以按语言、domain等进行区分。中文的估计更高。</p>
<p>产生spam的主要原因是一方面搜索引擎是web的入口，另一方面搜索引擎按page的质量进行排序，用户只关注top10的点击，这些点击带来了相当多的流量，spam的目的就是排在前面，以获得更好的流量。</p>
<p>spam的主要危害如下：<br>影响用户体验；<br>浪费资源；<br>对好网站不公平；</p>
<p>2 相关理论模型<br>所有rank相关的模型都涉及了，有些还没来得及细细研究。</p>
<p>tf-idf = sum(tf(t)*idf(t))     t是查询query与文档term的交集<br>tf:  单词占文章的百分比<br>idf: 单词在所有文档集合中的出现频率百分比的倒数<br>因为web的页面内容web owner可以随意修改，idf是全局的，一般认为spam没法控制，因此spam主要针对tf</p>
<p>VSM：<br>将文档document与查询query表示成term权重的向量，计算文档与查询的相似度以进行排序&lt;余弦距离是常用的方法&gt;</p>
<p>pagerank：<br>使用入链信息来打分<br>the importance of a certain page inﬂuences and is being inﬂuenced by the<br>importance of some other pages.</p>
<p>hits：<br>使用入链与出链信息来打分&lt;分别对应authority与hub得分&gt;<br>According to the circular deﬁnition of HITS, important hub pages are those that point to many important authority pages,while important authority pages are those pointed to by many hubs.<br>spam通过影响出链信息，再影响入链信息。</p>
<p>browserrank</p>
<p>query-click</p>
<p>rank factor：<br>前面的hits、pagerank等也是排序因子，按照[3]，排序因子主要可以分为 on the page factor + off the page factor。<br>具体可以参考[3]，对了解spam的产生原因有帮助。</p>
<p>评价标准：<br>查准率<br>查全率</p>
<p>3 分类<br>host/domain name spam:<br>购买过期域名、host堆积&lt;比如一个domain下N多个子host，这些子host的前缀通常是随机的数字或者常用的term&gt;，某些热门关键词的domain&lt;比如由热门词汇组成很长的domain，中间以-等分隔&gt;</p>
<p>content spam：<br>位置：web页面中的任何一个位置都可以。常用的比如title meta body anchor&lt;针对指向的page&gt; url。<br>策略主要可以分为重复(repeat)与隐藏(hide)。<br>重复:  单个单词重复(Repetition)<br>        大量词汇堆砌(Dumping)<br>        穿插(Weaving)：拷贝一篇好的页面，再在里面穿插些spam词汇或者链接<br>        短语堆积(Phrase stitching):从不同的文章里抽取些词汇再汇总<br>        链接堆积<br>隐藏：背景色与文本色一样的文本/链接<br>         可视化属性设置为false<br>        使用脚本生成文本与链接<br>        通过img的点击指向新链接<br>        size特别短小的文本&lt;用户不可见&gt;</p>
<p>link spam：<br>位置：出链(outlink)与入链(inlink)<br>出链：克隆好的导航网站/目录(open dir clone)，比如国外的dmoz.org、<a href="http://dir.yahoo.com等，国内的hao123等" target="_blank" rel="external">http://dir.yahoo.com等，国内的hao123等</a><br>入链：链接农场(link farm)：一堆链接的指向复杂度超出了阈值<br>        蜜罐(honey pot)：从别的网站里拷贝的一些好页面，里面包含了一些spam链接；open dir clone也可放入此类。<br>        在一些权威网站里贴垃圾链接(insert link at dir)<br>        在一些open的平台里帖链接，比如blog、wiki、social site、留言板<br>        友情链接交换(link exchange)<br>        购买过期的域名(expired domain)：在购买的废弃域名里张贴大量链接，主要废弃域名的排名会存在一段时间</p>
<p>关于隐藏(hiding)技术与重定向(redirect)技术：<br>有的论文将隐藏技术与重定向技术作为单独的一类spam技术进行划分。隐藏技术包括基于IP的(搜集特定crawler的IP)与基于HTTP协议头的User Agent(crawler一般会用这个字段标识自身)，另外前面所讲的基于内容的隐藏技术也划分到此类。重定向技术包括http协议重定向、meta重定向与JS重定向。</p>
<p>除去已划分到内容spam部分的基于内容的隐藏技术，剩下的个人认为没有多少意思。对于基于特定IP/http请求头的隐藏技术，检测方法很容易，无非是多次爬取，基于内容的比较，对于大的商业crawler，这样做貌似不够友好，也浪费资源；至于重定向，比如JS重定向，随着越来越多的好网页在特殊情况下也会使用这种技术，个人认为采用类似于V8的JS引擎，已可以检测出重定向后的URL，就不用考虑此类问题了。</p>
<p>用户的角度：<br>基于浏览行为的，<br>基于query点击的，</p>
<p>4 检测<br>content：基于规则的与基于统计的</p>
<p>link：link farm检测<br>pagerank分值较低的<br>trustrank分值<br>spamrank分值较高的<br>初始种子的选择：人工选择好的、差的，in link 与out link的交集&lt;不同domain的&gt; &gt; 阈值；</p>
<p>用户行为的事后分析：<br>click-model针对click-log<br>browser-model针对browse-log</p>
<p>附：参考<br>[1] Monika Henzinger, Rajeev Motwani, and Craig Silverstein. Challenges in web search engines. SIGIR Forum, 36(2), 2002.<br>[2] The Classification of Search Engine Spam  <a href="http://www.silverdisc.co.uk/articles/spam-classification" target="_blank" rel="external">http://www.silverdisc.co.uk/articles/spam-classification</a><br>[3] Web Spam Taxonomy<br>[4] Survey on web spam detection-principles and algorithms<br>[5] Alan Perkins. The classification of search engine spam. <a href="http://www.ebrandmanagement.com/whitepapers/spam-classification/" target="_blank" rel="external">http://www.ebrandmanagement.com/whitepapers/spam-classification/</a>.<br>[6] Zolt´an Gy¨ongyi and Hector Garcia-Molina. Link spam alliances. Technical report, Stanford University, 2005.</p>
<p>rank factor<br>google ranking factor: <a href="http://www.vaughns-1-pagers.com/internet/google-ranking-factors.htm" target="_blank" rel="external">http://www.vaughns-1-pagers.com/internet/google-ranking-factors.htm</a></p>
<p>pagerank<br>[1] Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. The PageRank citation ranking: Bringing order to the web. Technical report, Stanford University, 1998.<br>[2] Monica Bianchini, Marco Gori, and Franco Scarselli. Inside PageRank. ACM Transactions on Internet Technology, 5(1), 2005.<br>[3] T. Haveliwala. Efficient computation of PageRank. Tech. rep., Stanford University, 1999.<br>[4] T. Haveliwala. Topic-sensitive PageRank. In Proceedings of the Eleventh International Conference on World Wide Web, 2002.<br>[5] S. Kamvar, T. Haveliwala, C. Manning, and G. Golub. Extrapolation methods for accelerating PageRank computations. In Proceedings of the Twelfth International Conference on World Wide Web, 2003.<br>[6] A. Langville and C. Meyer. Deeper inside PageRank. Tech. rep., North Carolina State University, 2003.<br>[7] Jon Kleinberg. Authoritative sources in a hyperlinked environment. Journal of the ACM, 46(5), 1999.</p>
<p>anti-spam<br>[1] Dennis Fetterly, Mark Manasse, and Marc Najork. Spam, damn spam, and statistics. In Proceedings of the Seventh International Workshop on the Web and Databases (WebDB), 2004.<br>[2] Z. Gy¨ongyi and H. Garcia-Molina. Seed selection in TrustRank. Tech. rep., Stanford University, 2004.<br>[3] Pr0 - Google’s PageRank 0, <a href="http://pr.efactory.de/e-pr0.shtml" target="_blank" rel="external">http://pr.efactory.de/e-pr0.shtml</a>. 2002.<br>[4] Combating Web Spam with TrustRank<br>[5] Detecting Spam Web Pages through Content Analysis<br>[6] Identifying Link Farm Spam Pages<br>[7] Fighting against Web Spam: A Novel Propagation Method based on Click-through Data</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近对网页spam有兴趣，找了些论文看看，部分还没看完，做个小结吧，后续再慢慢看，慢慢补充了。&lt;br&gt;主要内容都是参考里的论文里的。&lt;/p&gt;
&lt;p&gt;1 spam基础&lt;br&gt;那些误导搜索引擎排名的行为或者从搜索引擎中获得不应有的利益的行为都可以称为spam，具体是否为spam取决于搜索引擎的判断标准。&lt;/p&gt;
&lt;p&gt;简单来说，那些搜索引擎明文允许进行的或者即使搜索引擎不存在但仍存在的“优化”行为可以认为不是spam。比如一些针对特定client、终端的优化行为不能认为是spam。再比如垃圾网站里贴出的链接，这些链接不应该作为spam，因为这些链接的存在超出了链接目的地的owner的控制，惩罚的应该是垃圾网站本身而不是它指向的链接。
    
    </summary>
    
      <category term="搜索引擎" scheme="http://www.petermao.com/categories/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"/>
    
    
      <category term="anti-spam" scheme="http://www.petermao.com/tags/anti-spam/"/>
    
      <category term="spam" scheme="http://www.petermao.com/tags/spam/"/>
    
      <category term="网页spam" scheme="http://www.petermao.com/tags/%E7%BD%91%E9%A1%B5spam/"/>
    
  </entry>
  
  <entry>
    <title>redis源代码分析25–VM（下）</title>
    <link href="http://www.petermao.com/redis/121/"/>
    <id>http://www.petermao.com/redis/121/</id>
    <published>2011-05-01T03:01:22.000Z</published>
    <updated>2017-02-14T02:02:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>这一节介绍下redis中的多线程机制。</p>
<p>先看看多线程换出的机制。</p>
<p>serverCron函数中调用 vmSwapOneObjectThreaded开始多线程方式换出value，vmSwapOneObjectThreaded会调用 vmSwapOneObject（参看上一节的解释），而vmSwapOneObject最终会调用vmSwapObjectThreaded。<a id="more"></a></p>
<pre>
static int vmSwapObjectThreaded(robj *key, robj *val, redisDb *db) {
    iojob *j;

    assert(key->storage == REDIS_VM_MEMORY);
    assert(key->refcount == 1);

    j = zmalloc(sizeof(*j));
    j->type = REDIS_IOJOB_PREPARE_SWAP;
    j->db = db;
    j->key = key;
    j->val = val;
    incrRefCount(val);
    j->canceled = 0;
    j->thread = (pthread_t) -1;
    key->storage = REDIS_VM_SWAPPING;

    lockThreadedIO();
    queueIOJob(j);
    unlockThreadedIO();
    return REDIS_OK;
}
</pre>
vmSwapObjectThreaded 会创建一个类型为REDIS_IOJOB_PREPARE_SWAP的job，然后使用queueIOJob来排队。而queueIOJob所做的主要工作就是就是将新job加入到server.io_newjobs，并在创建的线程数还没超过配置值时，创建新的线程。
<pre>
/* This function must be called while with threaded IO locked */
static void queueIOJob(iojob *j) {
    redisLog(REDIS_DEBUG,"Queued IO Job %p type %d about key '%s'\n",
        (void*)j, j->type, (char*)j->key->ptr);
    listAddNodeTail(server.io_newjobs,j);
    if (server.io_active_threads < server.vm_max_threads)
        spawnIOThread();
}
</pre>
从spawnIOThread中可以知道，新线程的入口点是IOThreadEntryPoint。
<pre>
static void spawnIOThread(void) {
    pthread_t thread;
    sigset_t mask, omask;
    int err;

    sigemptyset(&mask);
    sigaddset(&mask,SIGCHLD);
    sigaddset(&mask,SIGHUP);
    sigaddset(&mask,SIGPIPE);
    pthread_sigmask(SIG_SETMASK, &mask, &omask);
    while ((err = pthread_create(&thread,&server.io_threads_attr,IOThreadEntryPoint,NULL)) != 0) {
        redisLog(REDIS_WARNING,"Unable to spawn an I/O thread: %s",
            strerror(err));
        usleep(1000000);
    }
    pthread_sigmask(SIG_SETMASK, &omask, NULL);
    server.io_active_threads++;
}
</pre>
IOThreadEntryPoint会将io_newjobs中的job移入server.io_processing，然后在做完job类型的工作后（加载value/计算value所需交换页数/换出value），将job从server.io_processing移入io_processed中。然后往 server.io_ready_pipe_write所在的管道（io_ready_pipe_read、io_ready_pipe_write组成管道的两端）写入一个字节，让睡眠中的vmThreadedIOCompletedJob继续运行，该函数会做些后续工作。
<pre>
static void *IOThreadEntryPoint(void *arg) {
    iojob *j;
    listNode *ln;
    REDIS_NOTUSED(arg);

    pthread_detach(pthread_self());
    while(1) {
        /* Get a new job to process */
        lockThreadedIO();
        if (listLength(server.io_newjobs) == 0) {
            /* No new jobs in queue, exit. */
            redisLog(REDIS_DEBUG,"Thread %ld exiting, nothing to do",
                (long) pthread_self());
            server.io_active_threads--;
            unlockThreadedIO();
            return NULL;
        }
        ln = listFirst(server.io_newjobs);
        j = ln->value;
        listDelNode(server.io_newjobs,ln);
        /* Add the job in the processing queue */
        j->thread = pthread_self();
        listAddNodeTail(server.io_processing,j);
        ln = listLast(server.io_processing); /* We use ln later to remove it */
        unlockThreadedIO();
        redisLog(REDIS_DEBUG,"Thread %ld got a new job (type %d): %p about key '%s'",
            (long) pthread_self(), j->type, (void*)j, (char*)j->key->ptr);

        /* Process the Job */
        if (j->type == REDIS_IOJOB_LOAD) {
            j->val = vmReadObjectFromSwap(j->page,j->key->vtype);
        } else if (j->type == REDIS_IOJOB_PREPARE_SWAP) {
            FILE *fp = fopen("/dev/null","w+");
            j->pages = rdbSavedObjectPages(j->val,fp);
            fclose(fp);
        } else if (j->type == REDIS_IOJOB_DO_SWAP) {
            if (vmWriteObjectOnSwap(j->val,j->page) == REDIS_ERR)
                j->canceled = 1;
        }

        /* Done: insert the job into the processed queue */
        redisLog(REDIS_DEBUG,"Thread %ld completed the job: %p (key %s)",
            (long) pthread_self(), (void*)j, (char*)j->key->ptr);
        lockThreadedIO();
        listDelNode(server.io_processing,ln);
        listAddNodeTail(server.io_processed,j);
        unlockThreadedIO();

        /* Signal the main thread there is new stuff to process */
        assert(write(server.io_ready_pipe_write,"x",1) == 1);
    }
    return NULL; /* never reached */
}

static void vmThreadedIOCompletedJob(aeEventLoop *el, int fd, void *privdata,
            int mask)
{
    char buf[1];
    int retval, processed = 0, toprocess = -1, trytoswap = 1;
    REDIS_NOTUSED(el);
    REDIS_NOTUSED(mask);
    REDIS_NOTUSED(privdata);

    if (privdata != NULL) trytoswap = 0; /* check the comments above... */

    /* For every byte we read in the read side of the pipe, there is one
     * I/O job completed to process. */
    while((retval = read(fd,buf,1)) == 1) {
        iojob *j;
        listNode *ln;
        robj *key;
        struct dictEntry *de;

        redisLog(REDIS_DEBUG,"Processing I/O completed job");

        /* Get the processed element (the oldest one) */
        lockThreadedIO();
        assert(listLength(server.io_processed) != 0);
        if (toprocess == -1) {
            toprocess = (listLength(server.io_processed)*REDIS_MAX_COMPLETED_JOBS_PROCESSED)/100;
            if (toprocess <= 0)="" toprocess="1;" }="" ln="listFirst(server.io_processed);" j="ln-">value;
        listDelNode(server.io_processed,ln);
        unlockThreadedIO();
        /* If this job is marked as canceled, just ignore it */
        if (j->canceled) {
            freeIOJob(j);
            continue;
        }
        /* Post process it in the main thread, as there are things we
         * can do just here to avoid race conditions and/or invasive locks */
        redisLog(REDIS_DEBUG,"Job %p type: %d, key at %p (%s) refcount: %d\n", (void*) j, j->type, (void*)j->key, (char*)j->key->ptr, j->key->refcount);
        de = dictFind(j->db->dict,j->key);
        assert(de != NULL);
        key = dictGetEntryKey(de);
        if (j->type == REDIS_IOJOB_LOAD) {
            redisDb *db;

            /* Key loaded, bring it at home */
            key->storage = REDIS_VM_MEMORY;
            key->vm.atime = server.unixtime;
            vmMarkPagesFree(key->vm.page,key->vm.usedpages);
            redisLog(REDIS_DEBUG, "VM: object %s loaded from disk (threaded)",
                (unsigned char*) key->ptr);
            server.vm_stats_swapped_objects--;
            server.vm_stats_swapins++;
            dictGetEntryVal(de) = j->val;
            incrRefCount(j->val);
            db = j->db;
            freeIOJob(j);
            /* Handle clients waiting for this key to be loaded. */
            handleClientsBlockedOnSwappedKey(db,key);
        } else if (j->type == REDIS_IOJOB_PREPARE_SWAP) {
            /* Now we know the amount of pages required to swap this object.
             * Let's find some space for it, and queue this task again
             * rebranded as REDIS_IOJOB_DO_SWAP. */
            if (!vmCanSwapOut() ||
                vmFindContiguousPages(&j->page,j->pages) == REDIS_ERR)
            {
                /* Ooops... no space or we can't swap as there is
                 * a fork()ed Redis trying to save stuff on disk. */
                freeIOJob(j);
                key->storage = REDIS_VM_MEMORY; /* undo operation */
            } else {
                /* Note that we need to mark this pages as used now,
                 * if the job will be canceled, we'll mark them as freed
                 * again. */
                vmMarkPagesUsed(j->page,j->pages);
                j->type = REDIS_IOJOB_DO_SWAP;
                lockThreadedIO();
                queueIOJob(j);
                unlockThreadedIO();
            }
        } else if (j->type == REDIS_IOJOB_DO_SWAP) {
            robj *val;

            /* Key swapped. We can finally free some memory. */
            if (key->storage != REDIS_VM_SWAPPING) {
                printf("key->storage: %d\n",key->storage);
                printf("key->name: %s\n",(char*)key->ptr);
                printf("key->refcount: %d\n",key->refcount);
                printf("val: %p\n",(void*)j->val);
                printf("val->type: %d\n",j->val->type);
                printf("val->ptr: %s\n",(char*)j->val->ptr);
            }
            redisAssert(key->storage == REDIS_VM_SWAPPING);
            val = dictGetEntryVal(de);
            key->vm.page = j->page;
            key->vm.usedpages = j->pages;
            key->storage = REDIS_VM_SWAPPED;
            key->vtype = j->val->type;
            decrRefCount(val); /* Deallocate the object from memory. */
            dictGetEntryVal(de) = NULL;
            redisLog(REDIS_DEBUG,
                "VM: object %s swapped out at %lld (%lld pages) (threaded)",
                (unsigned char*) key->ptr,
                (unsigned long long) j->page, (unsigned long long) j->pages);
            server.vm_stats_swapped_objects++;
            server.vm_stats_swapouts++;
            freeIOJob(j);
            /* Put a few more swap requests in queue if we are still
             * out of memory */
            if (trytoswap && vmCanSwapOut() &&
                zmalloc_used_memory() > server.vm_max_memory)
            {
                int more = 1;
                while(more) {
                    lockThreadedIO();
                    more = listLength(server.io_newjobs) <
                            (unsigned) server.vm_max_threads;
                    unlockThreadedIO();
                    /* Don't waste CPU time if swappable objects are rare. */
                    if (vmSwapOneObjectThreaded() == REDIS_ERR) {
                        trytoswap = 0;
                        break;
                    }
                }
            }
        }
        processed++;
        if (processed == toprocess) return;
    }
    if (retval < 0 && errno != EAGAIN) {
        redisLog(REDIS_WARNING,
            "WARNING: read(2) error in vmThreadedIOCompletedJob() %s",
            strerror(errno));
    }
}
</=></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这一节介绍下redis中的多线程机制。&lt;/p&gt;
&lt;p&gt;先看看多线程换出的机制。&lt;/p&gt;
&lt;p&gt;serverCron函数中调用 vmSwapOneObjectThreaded开始多线程方式换出value，vmSwapOneObjectThreaded会调用 vmSwapOneObject（参看上一节的解释），而vmSwapOneObject最终会调用vmSwapObjectThreaded。
    
    </summary>
    
      <category term="redis" scheme="http://www.petermao.com/categories/redis/"/>
    
    
  </entry>
  
  <entry>
    <title>redis源代码分析24–VM（中）</title>
    <link href="http://www.petermao.com/redis/118/"/>
    <id>http://www.petermao.com/redis/118/</id>
    <published>2011-05-01T02:57:48.000Z</published>
    <updated>2017-02-14T02:02:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>VM根据value换进换出的策略又有两种使用方式：阻塞方式和多线程方式（server.vm_max_threads == 0为阻塞方式）。</p>
<p>这一节主要介绍阻塞方式。</p>
<p>redis 启动重建db（aof方式或者快照方式）时，可能会因为内存限制将某些value换出到磁盘，此时只使用阻塞方式换出 value（vmSwapOneObjectBlocking函数）。除此之外，redis只在serverCron函数（该函数事件处理章节分析过）中换出value。我们来看看serverCron中的处理代码，阻塞方式使用函数vmSwapOneObjectBlocking换出value，多线程方式使用函数vmSwapOneObjectThreaded换出value。<a id="more"></a></p>
<pre>
static int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {
    ---
    /* Swap a few keys on disk if we are over the memory limit and VM
     * is enbled. Try to free objects from the free list first. */
    if (vmCanSwapOut()) {
        while (server.vm_enabled && zmalloc_used_memory() >
                server.vm_max_memory)
        {
            ---
            if (tryFreeOneObjectFromFreelist() == REDIS_OK) continue;
            retval = (server.vm_max_threads == 0) ?
                        vmSwapOneObjectBlocking() :
                        vmSwapOneObjectThreaded();
            ---
        }
    }
    ---
    return 100;
}
</pre>
无论是阻塞方式vmSwapOneObjectBlocking换出value，还是多线程方式vmSwapOneObjectThreaded换出value，最终都调用vmSwapOneObject（调用参数不一样）来换出value。

vmSwapOneObject会对每个db，随机选择5项，计算它的swappability，然后如果是多线程方式，则调用vmSwapObjectThreaded来换出value，否则使用vmSwapObjectBlocking换出value。
<pre>
static int vmSwapOneObject(int usethreads) {
    int j, i;
    struct dictEntry *best = NULL;
    double best_swappability = 0;
    redisDb *best_db = NULL;
    robj *key, *val;

    for (j = 0; j < server.dbnum; j++) {
        redisDb *db = server.db+j;
        /* Why maxtries is set to 100?
         * Because this way (usually) we'll find 1 object even if just 1% - 2%
         * are swappable objects */
        int maxtries = 100;

        if (dictSize(db->dict) == 0) continue;
        for (i = 0; i < 5; i++) {
            dictEntry *de;
            double swappability;

            if (maxtries) maxtries--;
            de = dictGetRandomKey(db->dict);
            key = dictGetEntryKey(de);
            val = dictGetEntryVal(de);
            /* Only swap objects that are currently in memory.
             *
             * Also don't swap shared objects if threaded VM is on, as we
             * try to ensure that the main thread does not touch the
             * object while the I/O thread is using it, but we can't
             * control other keys without adding additional mutex. */
            if (key->storage != REDIS_VM_MEMORY ||
                (server.vm_max_threads != 0 && val->refcount != 1)) {
                if (maxtries) i--; /* don't count this try */
                continue;
            }
            val->vm.atime = key->vm.atime; /* atime is updated on key object */
            swappability = computeObjectSwappability(val);
            if (!best || swappability > best_swappability) {
                best = de;
                best_swappability = swappability;
                best_db = db;
            }
        }
    }
    if (best == NULL) return REDIS_ERR;
    key = dictGetEntryKey(best);
    val = dictGetEntryVal(best);

    redisLog(REDIS_DEBUG,"Key with best swappability: %s, %f",
        key->ptr, best_swappability);

    /* Unshare the key if needed */
    if (key->refcount > 1) {
        robj *newkey = dupStringObject(key);
        decrRefCount(key);
        key = dictGetEntryKey(best) = newkey;
    }
    /* Swap it */
    if (usethreads) {
        vmSwapObjectThreaded(key,val,best_db);
        return REDIS_OK;
    } else {
        if (vmSwapObjectBlocking(key,val) == REDIS_OK) {
            dictGetEntryVal(best) = NULL;
            return REDIS_OK;
        } else {
            return REDIS_ERR;
        }
    }
}
</pre>
vmSwapObjectBlocking会在计算所需的交换页后，阻塞性的将value写到vm文件中（函数vmWriteObjectOnSwap），最后标记相应vm页为已使用。
<pre>
static int vmSwapObjectBlocking(robj *key, robj *val) {
    off_t pages = rdbSavedObjectPages(val,NULL);
    off_t page;

    assert(key->storage == REDIS_VM_MEMORY);
    assert(key->refcount == 1);
    if (vmFindContiguousPages(&page,pages) == REDIS_ERR) return REDIS_ERR;
    if (vmWriteObjectOnSwap(val,page) == REDIS_ERR) return REDIS_ERR;
    key->vm.page = page;
    key->vm.usedpages = pages;
    key->storage = REDIS_VM_SWAPPED;
    key->vtype = val->type;
    decrRefCount(val); /* Deallocate the object from memory. */
    vmMarkPagesUsed(page,pages);
    redisLog(REDIS_DEBUG,"VM: object %s swapped out at %lld (%lld pages)",
        (unsigned char*) key->ptr,
        (unsigned long long) page, (unsigned long long) pages);
    server.vm_stats_swapped_objects++;
    server.vm_stats_swapouts++;
    return REDIS_OK;
}
</pre>
对于value的加载，如果是多线程方式，会使用blockClientOnSwappedKeys提前加载，但阻塞方式则只有到相应命令执行时才会加载。最终无论是阻塞方式还是多线程方式，都会调用lookupKey来查找key是否在内存中，若不在，则使用vmLoadObject加载value，该函数是阻塞式的读入value。
<pre>
static robj *lookupKey(redisDb *db, robj *key) {
    dictEntry *de = dictFind(db->dict,key);
    if (de) {
        robj *key = dictGetEntryKey(de);
        robj *val = dictGetEntryVal(de);

        if (server.vm_enabled) {
            if (key->storage == REDIS_VM_MEMORY ||
                key->storage == REDIS_VM_SWAPPING)
            {
                /* If we were swapping the object out, stop it, this key
                 * was requested. */
                if (key->storage == REDIS_VM_SWAPPING)
                    vmCancelThreadedIOJob(key);
                /* Update the access time of the key for the aging algorithm. */
                key->vm.atime = server.unixtime;
            } else {
                int notify = (key->storage == REDIS_VM_LOADING);

                /* Our value was swapped on disk. Bring it at home. */
                redisAssert(val == NULL);
                val = vmLoadObject(key);
                dictGetEntryVal(de) = val;

                /* Clients blocked by the VM subsystem may be waiting for
                 * this key... */
                if (notify) handleClientsBlockedOnSwappedKey(db,key);
            }
        }
        return val;
    } else {
        return NULL;
    }
}
</pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;VM根据value换进换出的策略又有两种使用方式：阻塞方式和多线程方式（server.vm_max_threads == 0为阻塞方式）。&lt;/p&gt;
&lt;p&gt;这一节主要介绍阻塞方式。&lt;/p&gt;
&lt;p&gt;redis 启动重建db（aof方式或者快照方式）时，可能会因为内存限制将某些value换出到磁盘，此时只使用阻塞方式换出 value（vmSwapOneObjectBlocking函数）。除此之外，redis只在serverCron函数（该函数事件处理章节分析过）中换出value。我们来看看serverCron中的处理代码，阻塞方式使用函数vmSwapOneObjectBlocking换出value，多线程方式使用函数vmSwapOneObjectThreaded换出value。
    
    </summary>
    
      <category term="redis" scheme="http://www.petermao.com/categories/redis/"/>
    
    
  </entry>
  
  <entry>
    <title>redis源代码分析23–VM（上）</title>
    <link href="http://www.petermao.com/redis/116/"/>
    <id>http://www.petermao.com/redis/116/</id>
    <published>2011-05-01T02:56:36.000Z</published>
    <updated>2017-02-14T02:02:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>VM是Redis2.0新增的一个功能。在没有VM之前，redis会把db中的所有数据放在内存中。随着redis的不断运行，所使用的内存会越来越大。但同时，client对某些数据的访问频度明显会比其他数据高。redis引入VM功能来试图解决这个问题。简言之，VM使得redis会把很少访问的value保存到磁盘中。但同时，所有value的key都放在内存中，这是为了让被换出的value的查找在启用VM前后性能差不多。</p>
<p>VM在redis中算是redis中最复杂的模块之一，我们分三节来介绍。这一节介绍redis的主要数据结构，下一节介绍非阻塞方式，最后一节介绍多线程方式。</p>
<p>我们先来看看redis中的通用对象结构redisObject ：<a id="more"></a></p>
<pre>
// VM启用时, 对象所处位置
#define REDIS_VM_MEMORY 0       /* The object is on memory */
#define REDIS_VM_SWAPPED 1      /* The object is on disk */
#define REDIS_VM_SWAPPING 2     /* Redis is swapping this object on disk */
#define REDIS_VM_LOADING 3      /* Redis is loading this object from disk */

/* The VM object structure */
struct redisObjectVM {
    off_t page;         /* the page at witch the object is stored on disk */
    off_t usedpages;    /* number of pages used on disk */
    time_t atime;       /* Last access time */
} vm;

/* The actual Redis Object */
// 通用类型
// 对于key，需额外标志保存value的位置、类型等
typedef struct redisObject {
    void *ptr;
    unsigned char type;
    unsigned char encoding;
    unsigned char storage;  /* If this object is a key, where is the value?
                             * REDIS_VM_MEMORY, REDIS_VM_SWAPPED, ... */
    unsigned char vtype; /* If this object is a key, and value is swapped out,
                          * this is the type of the swapped out object. */
    int refcount;
    /* VM fields, this are only allocated if VM is active, otherwise the
     * object allocation function will just allocate
     * sizeof(redisObjct) minus sizeof(redisObjectVM), so using
     * Redis without VM active will not have any overhead. */
    struct redisObjectVM vm;
} robj;
</pre>
robj 中的type保存了对象的类型，如string、list、set等。storage保存了该key对象对应的value所处的位置：内存、磁盘、正在被换出到磁盘，正在加载。vtype表示该key对象所对应的value的类型。page和usedpages保存了该key对象所对应的 value，atime是value的最后一次访问时间。因此，当robj所表示的key对象的storage类型为REDIS_VM_SWAPPED 时，就表示该key的value已不在内存中，需从VM中page的位置加载该value，vaue的类型为vtype，大小为usedpages。

创建对象的时候，根据是否启用VM机制，来分配合适大小的robj对象大小。
<pre>
static robj *createObject(int type, void *ptr) {
   ---
   else {
        if (server.vm_enabled) {
            pthread_mutex_unlock(&server.obj_freelist_mutex);
            o = zmalloc(sizeof(*o));
        } else {
            o = zmalloc(sizeof(*o)-sizeof(struct redisObjectVM));
        }
    }
    ---
    if (server.vm_enabled) {
        /* Note that this code may run in the context of an I/O thread
         * and accessing to server.unixtime in theory is an error
         * (no locks). But in practice this is safe, and even if we read
         * garbage Redis will not fail, as it's just a statistical info */
        o->vm.atime = server.unixtime;
        o->storage = REDIS_VM_MEMORY;
    }
    return o;
}
</pre>
VM的所有相关结构保存在redisServer 的如下几个字段中。
<pre>
 /* Global server state structure */
struct redisServer {
    ---
    /* Virtual memory state */
    FILE *vm_fp;
    int vm_fd;
    off_t vm_next_page; /* Next probably empty page */
    off_t vm_near_pages; /* Number of pages allocated sequentially */
    unsigned char *vm_bitmap; /* Bitmap of free/used pages */
    time_t unixtime;    /* Unix time sampled every second. */

    /* Virtual memory I/O threads stuff */
    /* An I/O thread process an element taken from the io_jobs queue and
     * put the result of the operation in the io_done list. While the
     * job is being processed, it's put on io_processing queue. */
    list *io_newjobs; /* List of VM I/O jobs yet to be processed */
    list *io_processing; /* List of VM I/O jobs being processed */
    list *io_processed; /* List of VM I/O jobs already processed */
    list *io_ready_clients; /* Clients ready to be unblocked. All keys loaded */
    pthread_mutex_t io_mutex; /* lock to access io_jobs/io_done/io_thread_job */
    pthread_mutex_t obj_freelist_mutex; /* safe redis objects creation/free */
    pthread_mutex_t io_swapfile_mutex; /* So we can lseek + write */
    pthread_attr_t io_threads_attr; /* attributes for threads creation */
    int io_active_threads; /* Number of running I/O threads */
    int vm_max_threads; /* Max number of I/O threads running at the same time */
    /* Our main thread is blocked on the event loop, locking for sockets ready
     * to be read or written, so when a threaded I/O operation is ready to be
     * processed by the main thread, the I/O thread will use a unix pipe to
     * awake the main thread. The followings are the two pipe FDs. */
    int io_ready_pipe_read;
    int io_ready_pipe_write;
    /* Virtual memory stats */
    unsigned long long vm_stats_used_pages;
    unsigned long long vm_stats_swapped_objects;
    unsigned long long vm_stats_swapouts;
    unsigned long long vm_stats_swapins;
   ---
};
</pre>
vm_fp 和vm_fd指向磁盘上的vm文件，通过这两个指针来读写vm文件。vm_bitmap管理着vm文件中每一页的分配与释放情况（每一项为0表示该页空闲，为1表示已使用）。每一页的大小通过vm-page-size来配置，页数通过vm-pages来配置。值得一提的是，redis中的每一页最多只能放置一个对象，一个对象可以放在连续的多个页上。unixtime只是缓存时间值，这在计算value的最近使用频率时会用到。接下来的结构跟多线程方式换出/换进vlue有关。使用多线程方式时，换进/换出value被看成一个个的job，job的类型有如下几种：
<pre>
/* VM threaded I/O request message */
#define REDIS_IOJOB_LOAD 0          /* Load from disk to memory */
#define REDIS_IOJOB_PREPARE_SWAP 1  /* Compute needed pages */
#define REDIS_IOJOB_DO_SWAP 2       /* Swap from memory to disk */

typedef struct iojob {
    int type;   /* Request type, REDIS_IOJOB_* */
    redisDb *db;/* Redis database */
    robj *key;  /* This I/O request is about swapping this key */
    robj *val;  /* the value to swap for REDIS_IOREQ_*_SWAP, otherwise this
                 * field is populated by the I/O thread for REDIS_IOREQ_LOAD. */
    off_t page; /* Swap page where to read/write the object */
    off_t pages; /* Swap pages needed to save object. PREPARE_SWAP return val */
    int canceled; /* True if this command was canceled by blocking side of VM */
    pthread_t thread; /* ID of the thread processing this entry */
} iojob;
</pre>
类型为REDIS_IOJOB_LOAD的job用来加载某个value，类型为REDIS_IOJOB_DO_SWAP的job就用来换出某个 value，在换出value之前，需要创建类型为REDIS_IOJOB_PREPARE_SWAP的job来计算所需的交换页数。

无论是上述3种中的哪一种，新建的job都会使用queueIOJob放在io_newjobs队列中，而线程入口函数IOThreadEntryPoint 会将io_newjobs中的job移入server.io_processing，然后在做完job类型的工作后（加载value/计算value所需交换页数/换出value），将job从server.io_processing移入io_processed中。然后往 server.io_ready_pipe_write所在的管道（io_ready_pipe_read、io_ready_pipe_write组成管道的两端）写入一个字节，让睡眠中的vmThreadedIOCompletedJob继续运行，该函数会做些后续工作。

io_ready_clients保存了可以继续运行的client链表（之前因为等待value已阻塞），后面几个结构跟多线程的保护和全局的vm统计有关。

VM的初始化在vmInit中，主要做的工作就是上面介绍的几个结构的初始化。除此之外，最重要的工作就是设置管道的read事件的处理函数vmThreadedIOCompletedJob，该函数会在管道可读时运行，跟多线程的运行密切相关。
<pre>
static void vmInit(void) {
    off_t totsize;
    int pipefds[2];
    size_t stacksize;
    struct flock fl;

    if (server.vm_max_threads != 0)
        zmalloc_enable_thread_safeness(); /* we need thread safe zmalloc() */

    redisLog(REDIS_NOTICE,"Using '%s' as swap file",server.vm_swap_file);
    /* Try to open the old swap file, otherwise create it */
    if ((server.vm_fp = fopen(server.vm_swap_file,"r+b")) == NULL) {
        server.vm_fp = fopen(server.vm_swap_file,"w+b");
    }
    if (server.vm_fp == NULL) {
        redisLog(REDIS_WARNING,
            "Can't open the swap file: %s. Exiting.",
            strerror(errno));
        exit(1);
    }
    server.vm_fd = fileno(server.vm_fp);
    /* Lock the swap file for writing, this is useful in order to avoid
     * another instance to use the same swap file for a config error. */
    fl.l_type = F_WRLCK;
    fl.l_whence = SEEK_SET;
    fl.l_start = fl.l_len = 0;
    if (fcntl(server.vm_fd,F_SETLK,&fl) == -1) {
        redisLog(REDIS_WARNING,
            "Can't lock the swap file at '%s': %s. Make sure it is not used by another Redis instance.", server.vm_swap_file, strerror(errno));
        exit(1);
    }
    /* Initialize */
    server.vm_next_page = 0;
    server.vm_near_pages = 0;
    server.vm_stats_used_pages = 0;
    server.vm_stats_swapped_objects = 0;
    server.vm_stats_swapouts = 0;
    server.vm_stats_swapins = 0;
    totsize = server.vm_pages*server.vm_page_size;
    redisLog(REDIS_NOTICE,"Allocating %lld bytes of swap file",totsize);
    if (ftruncate(server.vm_fd,totsize) == -1) {
        redisLog(REDIS_WARNING,"Can't ftruncate swap file: %s. Exiting.",
            strerror(errno));
        exit(1);
    } else {
        redisLog(REDIS_NOTICE,"Swap file allocated with success");
    }
    server.vm_bitmap = zmalloc((server.vm_pages+7)/8);
    redisLog(REDIS_VERBOSE,"Allocated %lld bytes page table for %lld pages",
        (long long) (server.vm_pages+7)/8, server.vm_pages);
    memset(server.vm_bitmap,0,(server.vm_pages+7)/8);

    /* Initialize threaded I/O (used by Virtual Memory) */
    server.io_newjobs = listCreate();
    server.io_processing = listCreate();
    server.io_processed = listCreate();
    server.io_ready_clients = listCreate();
    pthread_mutex_init(&server.io_mutex,NULL);
    pthread_mutex_init(&server.obj_freelist_mutex,NULL);
    pthread_mutex_init(&server.io_swapfile_mutex,NULL);
    server.io_active_threads = 0;
    if (pipe(pipefds) == -1) {
        redisLog(REDIS_WARNING,"Unable to intialized VM: pipe(2): %s. Exiting."
            ,strerror(errno));
        exit(1);
    }
    server.io_ready_pipe_read = pipefds[0];
    server.io_ready_pipe_write = pipefds[1];
    redisAssert(anetNonBlock(NULL,server.io_ready_pipe_read) != ANET_ERR);
    /* LZF requires a lot of stack */
    pthread_attr_init(&server.io_threads_attr);
    pthread_attr_getstacksize(&server.io_threads_attr, &stacksize);

    /* Solaris may report a stacksize of 0, let's set it to 1 otherwise 115     
     * multiplying it by 2 in the while loop later will not really help ;) */
    if (!stacksize) stacksize = 1;

    while (stacksize < REDIS_THREAD_STACK_SIZE) stacksize *= 2;
    pthread_attr_setstacksize(&server.io_threads_attr, stacksize);
    /* Listen for events in the threaded I/O pipe */
    if (aeCreateFileEvent(server.el, server.io_ready_pipe_read, AE_READABLE,
        vmThreadedIOCompletedJob, NULL) == AE_ERR)
        oom("creating file event");
}
</pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;VM是Redis2.0新增的一个功能。在没有VM之前，redis会把db中的所有数据放在内存中。随着redis的不断运行，所使用的内存会越来越大。但同时，client对某些数据的访问频度明显会比其他数据高。redis引入VM功能来试图解决这个问题。简言之，VM使得redis会把很少访问的value保存到磁盘中。但同时，所有value的key都放在内存中，这是为了让被换出的value的查找在启用VM前后性能差不多。&lt;/p&gt;
&lt;p&gt;VM在redis中算是redis中最复杂的模块之一，我们分三节来介绍。这一节介绍redis的主要数据结构，下一节介绍非阻塞方式，最后一节介绍多线程方式。&lt;/p&gt;
&lt;p&gt;我们先来看看redis中的通用对象结构redisObject ：
    
    </summary>
    
      <category term="redis" scheme="http://www.petermao.com/categories/redis/"/>
    
    
  </entry>
  
  <entry>
    <title>redis源代码分析22–协议</title>
    <link href="http://www.petermao.com/redis/114/"/>
    <id>http://www.petermao.com/redis/114/</id>
    <published>2011-05-01T02:55:03.000Z</published>
    <updated>2017-02-14T02:02:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>redis默认使用tcp协议的6379端口，其协议是文本行格式的而不是二进制格式的，每一行都以”\r\n”结尾，非常容易理解。</p>
<p>参考ProtocolSpecification.html就知道，发布到redis的命令有如下几种返回格式（对于不存在的值，会返回-1，此时client library应返回合适的nil对象（比如C语言的NULL），而不是空字符串）：</p>
<p>1）第一个字节是字符“-”，后面跟着一行出错信息（error reply）<a id="more"></a></p>
<p>比如lpop命令，当操作的对象不是一个链表时，会返回如下出错信息：</p>
<p>“-ERR Operation against a key holding the wrong kind of value\r\n”</p>
<p>2）第一个字节是字符“+”，后面跟着一行表示执行结果的提示信息（line reply）</p>
<p>比如set命令执行成功后，会返回”+OK\r\n”</p>
<p>3）第一个字节是字符“$”，后面先跟一行，仅有一个数字，该数字表示下一行字符的个数（若不存在，则数字为-1）（bulk reply）</p>
<p>比如get命令，成功时返回值的类似于“$7\r\nmyvalue”，不存在时返回的信息为“$-1\r\n”</p>
<p>4）第一个字节是字符“*”，后面先跟一行，仅有一个数字，该数字表示bulk reply的个数（若不存在，则数字为-1）（multi-bulk reply）</p>
<p>比如lrange命令，若要求返回0–2之间的值，则成功时返回值类似于”<em>3\r\n$6\r\nvalue1\r\n$7\r\nmyvalue\r\n$5\r\nhello\r\n”，不存在时返回的信息类似于”</em>-1\r\n”。</p>
<p>5）第一个字节是字符“:”，后面跟着一个整数值（integer reply）</p>
<p>比如incr命令，成功时会返回对象+1后的值。</p>
<p>而client发布命令的格式有如下几种，第一个字符串都必须是命令字，不同的参数之间用1个空格来分隔：<br>1）Inline Command:：仅一行 </p>
<p>比如 EXISTS命令，client发送的字节流类似于”EXISTS mykey\r\n”。<br>2）Bulk Command：类似于返回协议的bulk reply，一般有两行，第一行依次为“命令字 参数  一个数字”，该数字表示下一行字符的个数</p>
<p>比如SET命令，client发送的字节流类似于”SET mykey 5\r\nhello\r\n”。</p>
<p>3）multi-bulk Command：跟返回协议的multi-bulk reply类似。</p>
<p>比如上面的SET命令，用multi-bulk协议表示则为“*3\r\n$3\r\nSET\r\n$5\r\nmykey\r\n$5\r\nhello\r\n”。</p>
<p>尽管对于某些命令该协议发送的字节流比bulk command形式要多，但它可以支持任何一种命令，支持跟多个二进制安全参数的命令（bulk command仅支持一个），也可以使得client library不修改代码就能支持redis新发布的命令（只要把不支持的命令按multi-bulk形式发布即可）。redis的官方文档中还提到，未来可能仅支持client采用multi-bulk Command格式发布命令。</p>
<p>另外提一下，client library可以连续发布多条命令，而不是等到redis返回前一条命令的执行结果才发布新的命令，这种机制被称作pipelining，支持redis的client library大多支持这种机制，读者可自行参考。</p>
<p>最后来看看redis实现时用来返回信息的相关函数。</p>
<p>redis 会使用addReplySds、addReplyDouble、addReplyLongLong、addReplyUlong、 addReplyBulkLen、addReplyBulk、addReplyBulkCString等来打包不同的返回信息，最终调用addReply 来发送信息。</p>
<p>addReply会将发送信息添加到相应redisClient的reply链表尾部，并使用 sendReplyToClient来发送。sendReplyToClient会遍历reply链表，并依次发送，其间如果可以打包 reply（server.glueoutputbuf为真），则可以使用glueReplyBuffersIfNeeded把reply链表中的值合并到一个缓冲区，然后一次性发送。</p>
<p><pre><br>static void addReply(redisClient <em>c, robj </em>obj) {<br>    if (listLength(c-&gt;reply) == 0 &amp;&amp;<br>        (c-&gt;replstate == REDIS_REPL_NONE ||<br>         c-&gt;replstate == REDIS_REPL_ONLINE) &amp;&amp;<br>        aeCreateFileEvent(server.el, c-&gt;fd, AE_WRITABLE,<br>        sendReplyToClient, c) == AE_ERR) return;</pre></p>
<pre><code>if (server.vm_enabled &amp;&amp; obj-&gt;storage != REDIS_VM_MEMORY) {
    obj = dupStringObject(obj);
    obj-&gt;refcount = 0; /* getDecodedObject() will increment the refcount */
}
listAddNodeTail(c-&gt;reply,getDecodedObject(obj));
</code></pre><p>}</p>
<p>static void sendReplyToClient(aeEventLoop <em>el, int fd, void </em>privdata, int mask) {<br>    redisClient <em>c = privdata;<br>    int nwritten = 0, totwritten = 0, objlen;<br>    robj </em>o;<br>    REDIS_NOTUSED(el);<br>    REDIS_NOTUSED(mask);</p>
<pre><code>/* Use writev() if we have enough buffers to send */
if (!server.glueoutputbuf &amp;&amp;
    listLength(c-&gt;reply) &gt; REDIS_WRITEV_THRESHOLD &amp;&amp;
    !(c-&gt;flags &amp; REDIS_MASTER))
{
    sendReplyToClientWritev(el, fd, privdata, mask);
    return;
}

while(listLength(c-&gt;reply)) {
    if (server.glueoutputbuf &amp;&amp; listLength(c-&gt;reply) &gt; 1)
        glueReplyBuffersIfNeeded(c);

    o = listNodeValue(listFirst(c-&gt;reply));
    objlen = sdslen(o-&gt;ptr);

    if (objlen == 0) {
        listDelNode(c-&gt;reply,listFirst(c-&gt;reply));
        continue;
    }

    if (c-&gt;flags &amp; REDIS_MASTER) {
        /* Don&apos;t reply to a master */
        nwritten = objlen - c-&gt;sentlen;
    } else {
        nwritten = write(fd, ((char*)o-&gt;ptr)+c-&gt;sentlen, objlen - c-&gt;sentlen);
        if (nwritten &lt;= 0) break;
    }
    c-&gt;sentlen += nwritten;
    totwritten += nwritten;
    /* If we fully sent the object on head go to the next one */
    if (c-&gt;sentlen == objlen) {
        listDelNode(c-&gt;reply,listFirst(c-&gt;reply));
        c-&gt;sentlen = 0;
    }
    /* Note that we avoid to send more thank REDIS_MAX_WRITE_PER_EVENT
     * bytes, in a single threaded server it&apos;s a good idea to serve
     * other clients as well, even if a very large request comes from
     * super fast link that is always able to accept data (in real world
     * scenario think about &apos;KEYS *&apos; against the loopback interfae) */
    if (totwritten &gt; REDIS_MAX_WRITE_PER_EVENT) break;
}
if (nwritten == -1) {
    if (errno == EAGAIN) {
        nwritten = 0;
    } else {
        redisLog(REDIS_VERBOSE,
            &quot;Error writing to client: %s&quot;, strerror(errno));
        freeClient(c);
        return;
    }
}
if (totwritten &gt; 0) c-&gt;lastinteraction = time(NULL);
if (listLength(c-&gt;reply) == 0) {
    c-&gt;sentlen = 0;
    aeDeleteFileEvent(server.el,c-&gt;fd,AE_WRITABLE);
}
</code></pre><p>}<br><br>关于client library的实现，可按照前面介绍的格式自己实现，也可以阅读现有的client library来加深理解。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;redis默认使用tcp协议的6379端口，其协议是文本行格式的而不是二进制格式的，每一行都以”\r\n”结尾，非常容易理解。&lt;/p&gt;
&lt;p&gt;参考ProtocolSpecification.html就知道，发布到redis的命令有如下几种返回格式（对于不存在的值，会返回-1，此时client library应返回合适的nil对象（比如C语言的NULL），而不是空字符串）：&lt;/p&gt;
&lt;p&gt;1）第一个字节是字符“-”，后面跟着一行出错信息（error reply）
    
    </summary>
    
      <category term="redis" scheme="http://www.petermao.com/categories/redis/"/>
    
    
  </entry>
  
  <entry>
    <title>redis源代码分析21– 事务</title>
    <link href="http://www.petermao.com/redis/112/"/>
    <id>http://www.petermao.com/redis/112/</id>
    <published>2011-05-01T02:53:56.000Z</published>
    <updated>2017-02-14T02:02:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>redis的事务较简单，并不具备事务的acid的全部特征。主要原因之一是redis事务中的命令并不是立即执行的，会一直排队到发布exec命令才执行所有的命令；另一个主要原因是它不支持回滚，事务中的命令可以部分成功，部分失败，命令失败时跟不在事务上下文执行时返回的信息类似。不知道在未来会不会提供更好的支持。</p>
<p>我们且来看看现在redis事务的实现。</p>
<p>redis中跟事务相关的主要结构如下所示。每个redisClient的multiState保存了事务上下文要执行的命令。<a id="more"></a></p>
<p><pre><br>/<em> Client MULTI/EXEC state </em>/<br>typedef struct multiCmd {<br>    robj <em>*argv;<br>    int argc;<br>    struct redisCommand </em>cmd;<br>} multiCmd;</pre></p>
<p>typedef struct multiState {<br>    multiCmd <em>commands;     /</em> Array of MULTI commands <em>/<br>    int count;              /</em> Total number of MULTI commands */<br>} multiState;</p>
<h2 id="typedef-struct-redisClient"><a href="#typedef-struct-redisClient" class="headerlink" title="typedef struct redisClient {"></a>typedef struct redisClient {</h2><pre><code>multiState mstate;      /* MULTI/EXEC state */
---
</code></pre><p>} redisClient;<br><br>client通过发布multi命令进入事务上下文。处于事务上下文的client会设置REDIS_MULTI标志，multi命令会立即返回。</p>
<p><pre><br>static void multiCommand(redisClient *c) {<br>    c-&gt;flags |= REDIS_MULTI;<br>    addReply(c,shared.ok);<br>}<br></pre><br>处于事务上下文中的client会将在exec命令前发布的命令排队到mstate，并不立即执行相应命令且立即返回 shared.queued（如果之前参数检查不正确，则会返回出错信息，那就不会排队到mstate中），这在processCommand函数中反映出来（对processCommand的详细解释可参看前面命令处理章节）。queueMultiCommand只是简单的扩大mstate数组，并将当前命令加入其中。</p>
<p><pre></pre></p>
<h2 id="static-int-processCommand-redisClient-c"><a href="#static-int-processCommand-redisClient-c" class="headerlink" title="static int processCommand(redisClient *c) {"></a>static int processCommand(redisClient *c) {</h2><p>   /<em> Exec the command </em>/<br>    if (c-&gt;flags &amp; REDIS_MULTI &amp;&amp; cmd-&gt;proc != execCommand &amp;&amp; cmd-&gt;proc != discardCommand) {<br>        queueMultiCommand(c,cmd);<br>        addReply(c,shared.queued);<br>    } else {<br>        if (server.vm_enabled &amp;&amp; server.vm_max_threads &gt; 0 &amp;&amp;<br>            blockClientOnSwappedKeys(c,cmd)) return 1;<br>        call(c,cmd);</p>
<pre><code>}
---
</code></pre><p>}<br><br>当client发布exec命令时，则redis会调用execCommand来执行事务上下文中的命令集合。注意，在此之前，redis会使用execBlockClientOnSwappedKeys提前加载其命令集所需的key（该函数最终是调用前面介绍过的 waitForMultipleSwappedKeys来加载key）。因为这在命令表cmdTable是这样设置的：</p>
<p><pre><br>{“exec”,execCommand,1,REDIS_CMD_INLINE|REDIS_CMD_DENYOOM,execBlockClientOnSwappedKeys,0,0,0},<br></pre><br>execCommand会检查是不是处于事务上下文，然后使用execCommandReplicateMulti向 slave/monitor/aof（前提是使用这些功能）发送/写入multi命令字，因为multi命令本身没有排队，而execCommand会在执行完后写入exec命令的，必须让exec和multi命令配对，这之后就是调用call依次执行每个命令了。从这里没有检查call的返回就可以看出，如果命令执行失败了，只能由call命令本身返回出错信息，这里并不检查命令执行的成功与否，最后就是清空mstate中的命令字并取消 REDIS_MULTI状态了。</p>
<p><pre><br>static void execCommand(redisClient <em>c) {<br>    int j;<br>    robj *</em>orig_argv;<br>    int orig_argc;</pre></p>
<pre><code>if (!(c-&gt;flags &amp; REDIS_MULTI)) {
    addReplySds(c,sdsnew(&quot;-ERR EXEC without MULTI\r\n&quot;));
    return;
}

/* Replicate a MULTI request now that we are sure the block is executed.
 * This way we&apos;ll deliver the MULTI/..../EXEC block as a whole and
 * both the AOF and the replication link will have the same consistency
 * and atomicity guarantees. */
execCommandReplicateMulti(c);

/* Exec all the queued commands */
orig_argv = c-&gt;argv;
orig_argc = c-&gt;argc;
addReplySds(c,sdscatprintf(sdsempty(),&quot;*%d\r\n&quot;,c-&gt;mstate.count));
for (j = 0; j &lt; c-&gt;mstate.count; j++) {
    c-&gt;argc = c-&gt;mstate.commands[j].argc;
    c-&gt;argv = c-&gt;mstate.commands[j].argv;
    call(c,c-&gt;mstate.commands[j].cmd);
}
c-&gt;argv = orig_argv;
c-&gt;argc = orig_argc;
freeClientMultiState(c);
initClientMultiState(c);
c-&gt;flags &amp;= (~REDIS_MULTI);
/* Make sure the EXEC command is always replicated / AOF, since we
 * always send the MULTI command (we can&apos;t know beforehand if the
 * next operations will contain at least a modification to the DB). */
server.dirty++;
</code></pre><p>}<br><br>最后稍微提一下，如果事务上下文执行过程中，redis突然down掉，也就是最后的exec命令没有写入，此时会让 slave/monitor/aof处于不正确的状态。redis会在重启后会检查到这一情况，这是在loadAppendOnlyFile中完成的。当然这一检测执行的前提是down掉前和重启后都使用aof进行持久化。redis在检测到这一情况后，会退出程序。用户可调用用redis-check- aof工具进行修复。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;redis的事务较简单，并不具备事务的acid的全部特征。主要原因之一是redis事务中的命令并不是立即执行的，会一直排队到发布exec命令才执行所有的命令；另一个主要原因是它不支持回滚，事务中的命令可以部分成功，部分失败，命令失败时跟不在事务上下文执行时返回的信息类似。不知道在未来会不会提供更好的支持。&lt;/p&gt;
&lt;p&gt;我们且来看看现在redis事务的实现。&lt;/p&gt;
&lt;p&gt;redis中跟事务相关的主要结构如下所示。每个redisClient的multiState保存了事务上下文要执行的命令。
    
    </summary>
    
      <category term="redis" scheme="http://www.petermao.com/categories/redis/"/>
    
    
  </entry>
  
  <entry>
    <title>redis源代码分析20–发布/订阅</title>
    <link href="http://www.petermao.com/redis/110/"/>
    <id>http://www.petermao.com/redis/110/</id>
    <published>2011-05-01T02:52:44.000Z</published>
    <updated>2017-02-14T02:02:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>redis的发布/订阅（publish/subscribe）功能类似于传统的消息路由功能，发布者发布消息，订阅者接收消息，沟通发布者和订阅者之间的桥梁是订阅的channel或者pattern。发布者向指定的publish或者pattern发布消息，订阅者阻塞在订阅的channel或者pattern。可以看到，发布者不会指定哪个订阅者才能接收消息，订阅者也无法只接收特定发布者的消息。这种订阅者和发布者之间的关系是松耦合的，订阅者不知道是谁发布的消息，发布者也不知道谁会接收消息。</p>
<p>redis的发布/订阅功能主要通过SUBSCRIBE、UNSUBSCRIBE、PSUBSCRIBE、PUNSUBSCRIBE 、PUBLISH五个命令来表现。其中SUBSCRIBE、UNSUBSCRIBE用于订阅或者取消订阅channel，而PSUBSCRIBE、PUNSUBSCRIBE用于订阅或者取消订阅pattern，发布消息则通过publish命令。</p>
<p>对于发布/订阅功能的实现，我们先来看看几个与此相关的结构。<a id="more"></a></p>
<p><pre></pre></p>
<h2 id="struct-redisServer"><a href="#struct-redisServer" class="headerlink" title="struct redisServer {"></a>struct redisServer {</h2><p>   /<em> Pubsub </em>/<br>   dict <em>pubsub_channels;/</em> Map channels to list of subscribed clients */</p>
<h2 id="list-pubsub-patterns-A-list-of-pubsub-patterns"><a href="#list-pubsub-patterns-A-list-of-pubsub-patterns" class="headerlink" title="   list pubsub_patterns;/ A list of pubsub_patterns */"></a>   list <em>pubsub_patterns;/</em> A list of pubsub_patterns */</h2><p>}</p>
<h2 id="typedef-struct-redisClient"><a href="#typedef-struct-redisClient" class="headerlink" title="typedef struct redisClient {"></a>typedef struct redisClient {</h2><p>   dict <em>pubsub_channels; /</em> channels a client is interested in (SUBSCRIBE) <em>/<br>   list </em>pubsub_patterns; /<em> patterns a client is interested in (SUBSCRIBE) </em>/<br>} redisClient;<br><br>在redis的全局server变量（redisServer类型）中，channel和订阅者之间的关系用字典pubsub_channels来保存，特定channel和所有订阅者组成的链表构成pubsub_channels字典中的一项，即字典中的每一项可表示为（channel，订阅者链表）；pattern和订阅者之间的关系用链表pubsub_patterns来保存，链表中的每一项可表示成（pattern，redisClient）组成的字典。</p>
<p>在特定订阅者redisClient的结构中，pubsub_channels保存着它所订阅的channel的字典，而订阅的模式则保存在链表pubsub_patterns中。</p>
<p>从上面的解释，我们再来看看订阅/发布命令的最坏时间复杂度（注意字典增删查改一项的复杂度为O(1)，而链表的查删复杂度为O(N)，从链表尾部增加一项的复杂度为O(1)）。</p>
<p>SUBSCRIBE：</p>
<p>订阅者用SUBSCRIBE订阅特定channel，这需要在订阅者的redisClient结构中的pubsub_channels增加一项（复杂度为 O(1)），然后在redisServer 的pubsub_channels找到该channel（复杂度为O(1)），并在该channel的订阅者链表的尾部增加一项（复杂度为O(1)，注意，如果pubsub_channels中没找到该channel，则插入的复杂度也同为O(1)），因此订阅者用SUBSCRIBE订阅特定 channel的最坏时间复杂度为O(1)。</p>
<p>UNSUBSCRIBE：</p>
<p>订阅者取消订阅时，需要先从订阅者的redisClient结构中的pubsub_channels删除一项（复杂度为O(1)），然后在 redisServer 的pubsub_channels找到该channel（复杂度为O(1)），然后在channel的订阅者链表中删除该订阅者（复杂度为O(1)），因此总的复杂度为O(N)，N为特定channel的订阅者数。</p>
<p>PSUBSCRIBE：</p>
<p>订阅者用PSUBSCRIBE订阅pattern时，需要先在redisClient结构中的pubsub_patterns先查找是否已存在该 pattern（复杂度为O(N)），并在不存在的情况下往redisClient结构中的pubsub_patterns和redisServer结构中的pubsub_patterns链表尾部各增加一项（复杂度都为O(1)），因此，总的复杂度为O(N)，其中N为订阅者已订阅的模式。</p>
<p>PUNSUBSCRIBE：</p>
<p>订阅者用PUNSUBSCRIBE取消对pattern的订阅时，需要先在redisClient结构中的pubsub_patterns链表中删除该 pattern（复杂度为O(N)），并在redisServer结构中的pubsub_patterns链表中删除订阅者和pattern组成的映射（复杂度为O(M），因此，总的复杂度为O(N+M)，其中N为订阅者已订阅的模式，而M为系统中所有订阅者和所有pattern组成的映射数。</p>
<p>PUBLISH：</p>
<p>发布消息时，只会向特定channel发布，但该channel可能会匹配某个pattern。因此，需要先在redisServer结构中的 pubsub_channels找到该channel的订阅者链表（O(1)），然后发送给所有订阅者（复杂度为O(N)），然后查看 redisServer结构中的pubsub_patterns链表中的所有项，看channel是否和该项中的pattern匹配（复杂度为O(M)）（注意，这并不包括模式匹配的复杂度），因此，总的复杂度为O(N+M)，。其中N为该channel的订阅者数，而M为系统中所有订阅者和所有 pattern组成的映射数。另外，从这也可以看出，一个订阅者是可能多次收到同一个消息的。</p>
<p>解释了发布/订阅的算法后，其代码就好理解了，这里仅给出PUBLISH命令的处理函数publishCommand的代码，更多相关命令的代码请参看redis的源代码。</p>
<p><pre><br>static void publishCommand(redisClient *c) {<br>    int receivers = pubsubPublishMessage(c-&gt;argv[1],c-&gt;argv[2]);<br>    addReplyLongLong(c,receivers);<br>}</pre></p>
<p>/<em> Publish a message </em>/<br>static int pubsubPublishMessage(robj <em>channel, robj </em>message) {<br>    int receivers = 0;<br>    struct dictEntry <em>de;<br>    listNode </em>ln;<br>    listIter li;</p>
<pre><code>/* Send to clients listening for that channel */
de = dictFind(server.pubsub_channels,channel);
if (de) {
    list *list = dictGetEntryVal(de);
    listNode *ln;
    listIter li;

    listRewind(list,&amp;li);
    while ((ln = listNext(&amp;li)) != NULL) {
        redisClient *c = ln-&gt;value;

        addReply(c,shared.mbulk3);
        addReply(c,shared.messagebulk);
        addReplyBulk(c,channel);
        addReplyBulk(c,message);
        receivers++;
    }
}
/* Send to clients listening to matching channels */
if (listLength(server.pubsub_patterns)) {
    listRewind(server.pubsub_patterns,&amp;li);
    channel = getDecodedObject(channel);
    while ((ln = listNext(&amp;li)) != NULL) {
        pubsubPattern *pat = ln-&gt;value;

        if (stringmatchlen((char*)pat-&gt;pattern-&gt;ptr,
                            sdslen(pat-&gt;pattern-&gt;ptr),
                            (char*)channel-&gt;ptr,
                            sdslen(channel-&gt;ptr),0)) {
            addReply(pat-&gt;client,shared.mbulk4);
            addReply(pat-&gt;client,shared.pmessagebulk);
            addReplyBulk(pat-&gt;client,pat-&gt;pattern);
            addReplyBulk(pat-&gt;client,channel);
            addReplyBulk(pat-&gt;client,message);
            receivers++;
        }
    }
    decrRefCount(channel);
}
return receivers;
</code></pre><p>}<br><br>最后提醒一下，处于发布/订阅模式的client，是无法发布上述五种命令之外的命令（quit除外），这是在processCommand函数中检查的，可以参看前面命令处理章节对该函数的解释。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;redis的发布/订阅（publish/subscribe）功能类似于传统的消息路由功能，发布者发布消息，订阅者接收消息，沟通发布者和订阅者之间的桥梁是订阅的channel或者pattern。发布者向指定的publish或者pattern发布消息，订阅者阻塞在订阅的channel或者pattern。可以看到，发布者不会指定哪个订阅者才能接收消息，订阅者也无法只接收特定发布者的消息。这种订阅者和发布者之间的关系是松耦合的，订阅者不知道是谁发布的消息，发布者也不知道谁会接收消息。&lt;/p&gt;
&lt;p&gt;redis的发布/订阅功能主要通过SUBSCRIBE、UNSUBSCRIBE、PSUBSCRIBE、PUNSUBSCRIBE 、PUBLISH五个命令来表现。其中SUBSCRIBE、UNSUBSCRIBE用于订阅或者取消订阅channel，而PSUBSCRIBE、PUNSUBSCRIBE用于订阅或者取消订阅pattern，发布消息则通过publish命令。&lt;/p&gt;
&lt;p&gt;对于发布/订阅功能的实现，我们先来看看几个与此相关的结构。
    
    </summary>
    
      <category term="redis" scheme="http://www.petermao.com/categories/redis/"/>
    
    
  </entry>
  
  <entry>
    <title>redis源代码分析19–主从复制</title>
    <link href="http://www.petermao.com/redis/108/"/>
    <id>http://www.petermao.com/redis/108/</id>
    <published>2011-05-01T02:52:24.000Z</published>
    <updated>2017-02-14T02:02:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>先说下Redis主从复制的特点。</p>
<p>官方文档ReplicationHowto中提到以下特点：<br>1. 一个master支持多个slave<br>2. slave可以接受其他slave的连接，作为其他slave的master，从而形成一个master-slave的多级结构<br>3. 复制在master端是非阻塞的，也就是master在向client复制时可处理其他client的命令，而slave在第一次同步时是阻塞的<br>4. 复制被利用来提供可扩展性，比如可以将slave端用作数据冗余，也可以将耗时的命令（比如sort）发往某些slave从而避免master的阻塞，另外也可以用slave做持久化，这只需要将master的配置文件中的save指令注释掉。</p>
<p>client可以在一开始时作为slave连接master，也可以在运行后发布sync命令，从而跟master建立主从关系。</p>
<p>接下来我们分别从slave和master的视角概述下redis的主从复制的运行机制。<a id="more"></a></p>
<p> 如果redis作为slave运行，则全局变量server.replstate的状态有REDIS_REPL_NONE（不处于复制状态）、 REDIS_REPL_CONNECT（需要跟master建立连接）、REDIS_REPL_CONNECTED（已跟master建立连接）三种。在读入slaveof配置或者发布slaveof命令后，server.replstate取值为REDIS_REPL_CONNECT，然后在syncWithMaster跟master执行第一次同步后，取值变为REDIS_REPL_CONNECTED。</p>
<p>如果redis作为master运行，则对应某个客户端连接的变量slave.replstate的状态有REDIS_REPL_WAIT_BGSAVE_START（等待bgsave运行）、REDIS_REPL_WAIT_BGSAVE_END（bgsave已dump db，该bulk传输了）、REDIS_REPL_SEND_BULK（正在bulk传输）、REDIS_REPL_ONLINE（已完成开始的bulk传输，以后只需发送更新了）。对于slave客户端（发布sync命令），一开始slave.replstate都处于REDIS_REPL_WAIT_BGSAVE_START状态（后面详解syncCommand函数），然后在后台dump db后（backgroundSaveDoneHandler函数），处于REDIS_REPL_WAIT_BGSAVE_END 状态，然后updateSlavesWaitingBgsave会将状态置为REDIS_REPL_SEND_BULK，并设置write事件的函数 sendBulkToSlave，在sendBulkToSlave运行后，状态就变为REDIS_REPL_ONLINE了，此后master会一直调用replicationFeedSlaves给处于REDIS_REPL_ONLINE状态的slave发送新命令。</p>
<p>我们先看处于master端的redis会执行的代码。</p>
<p>slave端都是通过发布sync命令来跟master同步的，sync命令的处理函数syncCommand如下所示。</p>
<p>该函数中的注释足够明了。如果slave的client设置了REDIS_SLAVE标志，说明master已用syncCommand处理了该 slave。如果master还有对这个client的reply没有发送，则返回出错信息。此后若server.bgsavechildpid != -1且有slave处于REDIS_REPL_WAIT_BGSAVE_END状态，则说明dump db的后台进程刚结束，此时新的slave可直接用保存的rdb进行bulk传输（注意复制reply参数，因为master是非阻塞的，此时可能执行了一些命令，call函数会调用replicationFeedSlaves函数将命令参数保存到slave的reply参数中）。如果没有slave处于REDIS_REPL_WAIT_BGSAVE_END状态，但server.bgsavechildpid != -1，则说明bgsave后台进程没有运行完，需要等待其结束（bgsave后台进程结束后会处理等待的slave）。如果server.bgsavechildpid 等于 -1，则需要启动一个后台进程来dump db了。最后将当前client加到master的slaves链表中。</p>
<pre>
static void syncCommand(redisClient *c) {
    /* ignore SYNC if aleady slave or in monitor mode */
    if (c->flags & REDIS_SLAVE) return;

    /* SYNC can't be issued when the server has pending data to send to
     * the client about already issued commands. We need a fresh reply
     * buffer registering the differences between the BGSAVE and the current
     * dataset, so that we can copy to other slaves if needed. */
    if (listLength(c->reply) != 0) {
        addReplySds(c,sdsnew("-ERR SYNC is invalid with pending input\r\n"));
        return;
    }

    redisLog(REDIS_NOTICE,"Slave ask for synchronization");
    /* Here we need to check if there is a background saving operation
     * in progress, or if it is required to start one */
    if (server.bgsavechildpid != -1) {
        /* Ok a background save is in progress. Let's check if it is a good
         * one for replication, i.e. if there is another slave that is
         * registering differences since the server forked to save */
        redisClient *slave;
        listNode *ln;
        listIter li;

        listRewind(server.slaves,&li);
        while((ln = listNext(&li))) {
            slave = ln->value;
            if (slave->replstate == REDIS_REPL_WAIT_BGSAVE_END) break;
        }
        if (ln) {
            /* Perfect, the server is already registering differences for
             * another slave. Set the right state, and copy the buffer. */
            listRelease(c->reply);
            c->reply = listDup(slave->reply);
            c->replstate = REDIS_REPL_WAIT_BGSAVE_END;
            redisLog(REDIS_NOTICE,"Waiting for end of BGSAVE for SYNC");
        } else {
            /* No way, we need to wait for the next BGSAVE in order to
             * register differences */
            c->replstate = REDIS_REPL_WAIT_BGSAVE_START;
            redisLog(REDIS_NOTICE,"Waiting for next BGSAVE for SYNC");
        }
    } else {
        /* Ok we don't have a BGSAVE in progress, let's start one */
        redisLog(REDIS_NOTICE,"Starting BGSAVE for SYNC");
        if (rdbSaveBackground(server.dbfilename) != REDIS_OK) {
            redisLog(REDIS_NOTICE,"Replication failed, can't BGSAVE");
            addReplySds(c,sdsnew("-ERR Unalbe to perform background save\r\n"));
            return;
        }
        c->replstate = REDIS_REPL_WAIT_BGSAVE_END;
    }
    c->repldbfd = -1;
    c->flags |= REDIS_SLAVE;
    c->slaveseldb = 0;
    listAddNodeTail(server.slaves,c);
    return;
}
</pre>
此后slave无论处于REDIS_REPL_WAIT_BGSAVE_START还是REDIS_REPL_WAIT_BGSAVE_END，都只能等 dump db的后台进程运行结束后才会被处理。该进程结束后会执行backgroundSaveDoneHandler函数，而该函数调用 updateSlavesWaitingBgsave来处理slaves。

updateSlavesWaitingBgsave和syncCommand一样，涉及到slave的几个状态变换。对于等待dump db的slave，master都会将其放入server.slaves 链表中。此时，若slave->replstate == REDIS_REPL_WAIT_BGSAVE_START，说明当前dump db不是该slave需要的，redis需要重新启动后台进程来dump db。若slave->replstate == REDIS_REPL_WAIT_BGSAVE_END，则说明当前dump db正是该slave所需要的，此时设置slave的write事件的处理函数sendBulkToSlave。
<pre>
static void updateSlavesWaitingBgsave(int bgsaveerr) {
    listNode *ln;
    int startbgsave = 0;
    listIter li;

    listRewind(server.slaves,&li);
    while((ln = listNext(&li))) {
        redisClient *slave = ln->value;

        if (slave->replstate == REDIS_REPL_WAIT_BGSAVE_START) {
            startbgsave = 1;
            slave->replstate = REDIS_REPL_WAIT_BGSAVE_END;
        } else if (slave->replstate == REDIS_REPL_WAIT_BGSAVE_END) {
            struct redis_stat buf;

            if (bgsaveerr != REDIS_OK) {
                freeClient(slave);
                redisLog(REDIS_WARNING,"SYNC failed. BGSAVE child returned an error");
                continue;
            }
            if ((slave->repldbfd = open(server.dbfilename,O_RDONLY)) == -1 ||
                redis_fstat(slave->repldbfd,&buf) == -1) {
                freeClient(slave);
                redisLog(REDIS_WARNING,"SYNC failed. Can't open/stat DB after BGSAVE: %s", strerror(errno));
                continue;
            }
            slave->repldboff = 0;
            slave->repldbsize = buf.st_size;
            slave->replstate = REDIS_REPL_SEND_BULK;
            aeDeleteFileEvent(server.el,slave->fd,AE_WRITABLE);
            if (aeCreateFileEvent(server.el, slave->fd, AE_WRITABLE, sendBulkToSlave, slave) == AE_ERR) {
                freeClient(slave);
                continue;
            }
        }
    }
    if (startbgsave) {
        if (rdbSaveBackground(server.dbfilename) != REDIS_OK) {
            listIter li;

            listRewind(server.slaves,&li);
            redisLog(REDIS_WARNING,"SYNC failed. BGSAVE failed");
            while((ln = listNext(&li))) {
                redisClient *slave = ln->value;

                if (slave->replstate == REDIS_REPL_WAIT_BGSAVE_START)
                    freeClient(slave);
            }
        }
    }
}
</pre>
sendBulkToSlave 的逻辑不复杂。它根据slave->repldbfd指向的db，先从dump后的rdb文件中读入db数据，然后发送。发送完后会删除write 事件，设置slave->replstate状态为REDIS_REPL_ONLINE，此后master就会在收到命令后调用call函数，然后使用replicationFeedSlaves同步更新该slave了。replicationFeedSlaves也是遍历slave链表，对处于REDIS_REPL_ONLINE状态的slave，发送当前命令及其参数。
<pre>
 static void sendBulkToSlave(aeEventLoop *el, int fd, void *privdata, int mask) {
    redisClient *slave = privdata;
    REDIS_NOTUSED(el);
    REDIS_NOTUSED(mask);
    char buf[REDIS_IOBUF_LEN];
    ssize_t nwritten, buflen;

    if (slave->repldboff == 0) {
        /* Write the bulk write count before to transfer the DB. In theory here
         * we don't know how much room there is in the output buffer of the
         * socket, but in pratice SO_SNDLOWAT (the minimum count for output
         * operations) will never be smaller than the few bytes we need. */
        sds bulkcount;

        bulkcount = sdscatprintf(sdsempty(),"$%lld\r\n",(unsigned long long)
            slave->repldbsize);
        if (write(fd,bulkcount,sdslen(bulkcount)) != (signed)sdslen(bulkcount))
        {
            sdsfree(bulkcount);
            freeClient(slave);
            return;
        }
        sdsfree(bulkcount);
    }
    lseek(slave->repldbfd,slave->repldboff,SEEK_SET);
    buflen = read(slave->repldbfd,buf,REDIS_IOBUF_LEN);
    if (buflen <= 0)="" {="" redislog(redis_warning,"read="" error="" sending="" db="" to="" slave:="" %s",="" (buflen="=" ?="" "premature="" eof"="" :="" strerror(errno));="" freeclient(slave);="" return;="" }="" if="" ((nwritten="write(fd,buf,buflen))" =="-1)" redislog(redis_verbose,"write="" slave-="">repldboff += nwritten;
    if (slave->repldboff == slave->repldbsize) {
        close(slave->repldbfd);
        slave->repldbfd = -1;
        aeDeleteFileEvent(server.el,slave->fd,AE_WRITABLE);
        slave->replstate = REDIS_REPL_ONLINE;
        if (aeCreateFileEvent(server.el, slave->fd, AE_WRITABLE,
            sendReplyToClient, slave) == AE_ERR) {
            freeClient(slave);
            return;
        }
        addReplySds(slave,sdsempty());
        redisLog(REDIS_NOTICE,"Synchronization with slave succeeded");
    }
}
</=></pre>
接下来我们看看redis作为slave是如何运行的。

redis 作为slave（当然也可以使用普通的client作为slave端，这样则跟具体client的实现有关了）时，需要在配置文件中指明master的位置，在loadServerConfig读取配置参数时，会将server.replstate设置为REDIS_REPL_CONNECT状态。处于此状态的redis需要运行到serverCron后才能使用syncWithMaster来和master进行初始同步。查看syncWithMaster的代码可知，其实也向master发布sync命令来建立主从关系的，另外，该函数接收、发送数据时使用的是syncRead、syncWrite函数，而这些函数是阻塞的，因此，redis作为slave运行时，建立最初的主从关系时也是阻塞的。
<pre>
 /* Check if we should connect to a MASTER */
    if (server.replstate == REDIS_REPL_CONNECT && !(loops % 10)) {
        redisLog(REDIS_NOTICE,"Connecting to MASTER...");
        if (syncWithMaster() == REDIS_OK) {
            redisLog(REDIS_NOTICE,"MASTER <-> SLAVE sync succeeded");
            if (server.appendonly) rewriteAppendOnlyFileBackground();
        }
    }
</-></pre>
另外跟主从复制有关的一个命令就是slaveof命令。此命令是redis主从状态的转换函数，通过前面的分析可知，这只需要更改几个状态即可。
<pre>
static void slaveofCommand(redisClient *c) {
    if (!strcasecmp(c->argv[1]->ptr,"no") &&
        !strcasecmp(c->argv[2]->ptr,"one")) {
        if (server.masterhost) {
            sdsfree(server.masterhost);
            server.masterhost = NULL;
            if (server.master) freeClient(server.master);
            server.replstate = REDIS_REPL_NONE;
            redisLog(REDIS_NOTICE,"MASTER MODE enabled (user request)");
        }
    } else {
        sdsfree(server.masterhost);
        server.masterhost = sdsdup(c->argv[1]->ptr);
        server.masterport = atoi(c->argv[2]->ptr);
        if (server.master) freeClient(server.master);
        server.replstate = REDIS_REPL_CONNECT;
        redisLog(REDIS_NOTICE,"SLAVE OF %s:%d enabled (user request)",
            server.masterhost, server.masterport);
    }
    addReply(c,shared.ok);
}
</pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;先说下Redis主从复制的特点。&lt;/p&gt;
&lt;p&gt;官方文档ReplicationHowto中提到以下特点：&lt;br&gt;1. 一个master支持多个slave&lt;br&gt;2. slave可以接受其他slave的连接，作为其他slave的master，从而形成一个master-slave的多级结构&lt;br&gt;3. 复制在master端是非阻塞的，也就是master在向client复制时可处理其他client的命令，而slave在第一次同步时是阻塞的&lt;br&gt;4. 复制被利用来提供可扩展性，比如可以将slave端用作数据冗余，也可以将耗时的命令（比如sort）发往某些slave从而避免master的阻塞，另外也可以用slave做持久化，这只需要将master的配置文件中的save指令注释掉。&lt;/p&gt;
&lt;p&gt;client可以在一开始时作为slave连接master，也可以在运行后发布sync命令，从而跟master建立主从关系。&lt;/p&gt;
&lt;p&gt;接下来我们分别从slave和master的视角概述下redis的主从复制的运行机制。
    
    </summary>
    
      <category term="redis" scheme="http://www.petermao.com/categories/redis/"/>
    
    
  </entry>
  
  <entry>
    <title>redis源代码分析18–持久化之aof</title>
    <link href="http://www.petermao.com/redis/106/"/>
    <id>http://www.petermao.com/redis/106/</id>
    <published>2011-05-01T02:49:18.000Z</published>
    <updated>2017-02-14T02:02:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>Redis的aof功能的目的是在性能和持久化粒度上对持久化机制提供更好的支持。</p>
<p>快照方式持久化的粒度有时间（秒）和改变的key数两种，如果持久化的粒度较小，对性能会有较大的影响，因为每次都是dump整个db；如果持久化的粒度较大，则在指定时间内指定数目的数据的持久化无法保证。而aof持久化的粒度是每次会修改db数据的命令，因此粒度是最小的了，跟日志方式有点类似，由于仅记录一条命令，性能也最好。另外，跟日志类似，aof文件会越来越大，则可以通过执行BGREWRITEAOF命令在后台重建该文件。</p>
<p>我们先来看看redis如何记录命令的。</p>
<p>call函数是命令执行的函数（前面命令处理章节已详细介绍过该函数）。如果命令执行前后数据有修改，则server.dirty的取值会有变化。在启用了aof机制的情况下，call函数会调用feedAppendOnlyFile保存命令及其相关参数。<a id="more"></a></p>
<pre>
static void call(redisClient *c, struct redisCommand *cmd){
   long long dirty;
   dirty = server.dirty;
   cmd->proc(c);
   dirty = server.dirty-dirty;
   if(server.appendonly && dirty)
       feedAppendOnlyFile(cmd,c->db->id,c->argv,c->argc);
   ---
}
</pre>
feedAppendOnlyFile会首先检查当前命令所处的db是否跟前一条命令执行所处db一致。若不一致，则需要发布一条选择db的select命令，然后做些命令的转换工作（代码略去）。

紧接着，将命令参数所对应的buf保存到server.aofbuf中，该参数保存了一段时间内redis执行的命令及其参数，redis会在适当的时机将其刷到磁盘上的aof文件中；然后如果有后台重建aof文件，则也将该缓冲区保存到server.bgrewritebuf中，该缓冲区保存了重建aof文件的后台进程运行时redis所执行的命令及其参数，后台进程退出时需要将这些命令保存到重建文件中。
<pre>
static void feedAppendOnlyFile(struct redisCommand *cmd, int dictid, robj **argv, int argc){
   ---
   server.aofbuf = sdscatlen(server.aofbuf,buf,sdslen(buf));
   ---
   if(server.bgrewritechildpid != -1)
       server.bgrewritebuf = sdscatlen(server.bgrewritebuf,buf,sdslen(buf));
   sdsfree(buf);
}
</pre>
我们来看看server.aofbuf会在什么时机被刷新到磁盘aof文件中。

刷新采用的是flushAppendOnlyFile函数。该函数在beforeSleep中会被调用（事件处理章节已介绍过该函数），而该函数是在处理client事件之前执行执行的（事件循环函数aeMain是先执行beforesleep，然后执行aeProcessEvents），因此，server.aofbuf中的值会在向client发送响应之前刷新到磁盘上。

flushAppendOnlyFile调用write一次性写全部server.aofbuf缓冲区中的数据，并根据配置的同步策略，调用aof_fsync（对系统同步函数fsync的保证）进行同步，这样新的命令及其参数就被附加到aof文件当中了。
<pre>
static void flushAppendOnlyFile(void){
   time_t now;
   ssize_t nwritten;
   ---
    nwritten = write(server.appendfd,server.aofbuf,sdslen(server.aofbuf));
   ---
   sdsfree(server.aofbuf);
   server.aofbuf = sdsempty();

   /* Fsync if needed */
   now = time(NULL);
   if(server.appendfsync == APPENDFSYNC_ALWAYS||
        (server.appendfsync == APPENDFSYNC_EVERYSEC &&
        now-server.lastfsync > 1))
   {
       /* aof_fsync is defined as fdatasync() for Linux in order to avoid
         * flushing metadata. */
       aof_fsync(server.appendfd);/* Let's try to get this data on the disk */
       server.lastfsync = now;
   }
}
</pre>
接下来我们看看后台如何重建aof文件。

aof重建靠调用rewriteAppendOnlyFileBackground函数完成。查看该函数的调用关系就可以知道，该函数会在收到bgrewriteaof命令后执行，也会在收到config命令并且从不使用aof机制到开启aof机制时被调用，也会在运行redis的系统作为slave时，跟master建立连接后并在serverCron函数中执行syncWithMaster时调用。
rewriteAppendOnlyFileBackground重建aof的主要逻辑如下（代码略去）：

1）使用fork创建一个子进程

2）子进程调用rewriteAppendOnlyFile在一个临时文件里写能够反映当前db状态的数据和命令，

     此时父进程会把这段时间内执行的能够改变当前db数据的命令放到server.bgrewritebuf中（参看前面对feedAppendOnlyFile的解释）

3）当子进程退出时，父进程收到信号，将上面的内存缓冲区中的数据flush到临时文件中，然后将临时文件rename成新的aof文件（backgroundRewriteDoneHandler）。

父进程会在serverCron函数中等待执行aof重写或者快照保存的子进程，代码如下：
<pre>
/* Check if a background saving or AOF rewrite in progress terminated */
  if(server.bgsavechildpid != -1||server.bgrewritechildpid != -1){
      int statloc;
      pid_t pid;

      if((pid = wait3(&statloc,WNOHANG,NULL))!= 0){
          if(pid == server.bgsavechildpid){
              backgroundSaveDoneHandler(statloc);
          } else {
              backgroundRewriteDoneHandler(statloc);
          }
          updateDictResizePolicy();
      }
  }
</pre>
rewriteAppendOnlyFile将反映当前db状态的命令和参数写到一个临时文件中。该函数遍历db中的每条数据，redis中的db其实是一个大的hash表，每一条数据都用（key,val）来表示。从key可以知道val的类型（redis支持REDIS_STRING、REDIS_LIST、REDIS_SET、REDIS_ZSET、REDIS_HASH五种数据类型），然后解码val中的数据。写入时，按照客户端执行命令的形式写入。比如对于REDIS_STRING类型，则先写入"*3\r\n$3\r \nSET\r\n"，然后写入set的key，然后写入val；对于REDIS_LIST类型，将val强制转换为list类型后，先写入"*3\r \n$5\r\nRPUSH\r\n"，然后写入要操作的list的名字，然后写入list的第一个数据，循环前面3个步骤直到list遍历完；对于REDIS_SET类型，则对于每条数据先写入"*3\r\n$4\r\nSADD\r\n"；对于REDIS_ZSET类型，则对于每条数据先写入"*4\r\n$4\r\nZADD\r\n"；对于REDIS_HASH类型，则对于每条数据先写入"*4\r\n$4\r\nHSET\r\n"（代码简单但较琐碎，略去）。

最后我们介绍下redis启动时使用aof重建db的步骤。

启动时重建的关键是构建一个fake client，然后使用这个client向server发送从aof文件中读入的命令。
<pre>
int loadAppendOnlyFile(char *filename){
   ---
   fakeClient = createFakeClient();
   while(1){
       ---
       if(fgets(buf,sizeof(buf),fp)== NULL){
          ---
       }
      // 解析buf为对应的命令及参数
      // 查找命令
       cmd = lookupCommand(argv[0]->ptr);
      ---

      // 执行命令
       cmd->proc(fakeClient);
     ---
   }
   ---
}
</pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Redis的aof功能的目的是在性能和持久化粒度上对持久化机制提供更好的支持。&lt;/p&gt;
&lt;p&gt;快照方式持久化的粒度有时间（秒）和改变的key数两种，如果持久化的粒度较小，对性能会有较大的影响，因为每次都是dump整个db；如果持久化的粒度较大，则在指定时间内指定数目的数据的持久化无法保证。而aof持久化的粒度是每次会修改db数据的命令，因此粒度是最小的了，跟日志方式有点类似，由于仅记录一条命令，性能也最好。另外，跟日志类似，aof文件会越来越大，则可以通过执行BGREWRITEAOF命令在后台重建该文件。&lt;/p&gt;
&lt;p&gt;我们先来看看redis如何记录命令的。&lt;/p&gt;
&lt;p&gt;call函数是命令执行的函数（前面命令处理章节已详细介绍过该函数）。如果命令执行前后数据有修改，则server.dirty的取值会有变化。在启用了aof机制的情况下，call函数会调用feedAppendOnlyFile保存命令及其相关参数。
    
    </summary>
    
      <category term="redis" scheme="http://www.petermao.com/categories/redis/"/>
    
    
  </entry>
  
  <entry>
    <title>redis源代码分析17–持久化之快照</title>
    <link href="http://www.petermao.com/redis/104/"/>
    <id>http://www.petermao.com/redis/104/</id>
    <published>2011-05-01T02:45:26.000Z</published>
    <updated>2017-02-14T02:02:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>redis的持久化支持快照方式。快照方式会将整个db dump到磁盘上。</p>
<p>client 可以发布save/bgsave命令让server将db dump到磁盘上。其中bgsave会执行后台dump（新建子进程执行dump），而save是阻塞式的dump db，会影响其他client的命令执行。除了发布命令执行快照保存外，redis的serverCron也会按照配置的参数执行后台dump，另外 slave建立连接时，master也会执行一个后台dump，然后才发送数据给slave（这在主从复制一节中介绍）。<a id="more"></a></p>
<pre>
static int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {
    ---
/* Check if a background saving or AOF rewrite in progress terminated */
    if (server.bgsavechildpid != -1 || server.bgrewritechildpid != -1) {
      ---
    }
else {
        /* If there is not a background saving in progress check if
         * we have to save now */
         time_t now = time(NULL);
         for (j = 0; j < server.saveparamslen; j++) {
            struct saveparam *sp = server.saveparams+j;

            if (server.dirty >= sp->changes &&
                now-server.lastsave > sp->seconds) {
                redisLog(REDIS_NOTICE,"%d changes in %d seconds. Saving...",
                    sp->changes, sp->seconds);
                rdbSaveBackground(server.dbfilename);
                break;
            }
         }
}
---
}
</pre>
无论是新建子进程还是阻塞式的执行快照方式（新建子进程方式会先调用rdbSaveBackground），最终都会调用rdbSave来保存db。

在rdbSave中可以看到，redis是按type、key、val方式来保存db中的数据的。

rdbLoad是快照方式保存数据后server启动时加载数据的函数，是rdbSave的逆过程。
<pre>
static int rdbSave(char *filename) {

    ---
    for (j = 0; j < server.dbnum; j++) {
        redisDb *db = server.db+j;
       ---
        /* Iterate this DB writing every entry */
        while((de = dictNext(di)) != NULL) {
            robj *key = dictGetEntryKey(de);
            robj *o = dictGetEntryVal(de);
            time_t expiretime = getExpire(db,key);
            ---
            /* Save type, key, value */
           if (rdbSaveType(fp,o->type) == -1) goto werr;
          if (rdbSaveStringObject(fp,key) == -1) goto werr;
          if (rdbSaveObject(fp,o) == -1) goto werr;
          ---
        }
        dictReleaseIterator(di);
    }
    ---
    /* Use RENAME to make sure the DB file is changed atomically only
     * if the generate DB file is ok. */
    if (rename(tmpfile,filename) == -1) {
        redisLog(REDIS_WARNING,"Error moving temp DB file on the final destination: %s", strerror(errno));
        unlink(tmpfile);
        return REDIS_ERR;
    }
    ---
}
</pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;redis的持久化支持快照方式。快照方式会将整个db dump到磁盘上。&lt;/p&gt;
&lt;p&gt;client 可以发布save/bgsave命令让server将db dump到磁盘上。其中bgsave会执行后台dump（新建子进程执行dump），而save是阻塞式的dump db，会影响其他client的命令执行。除了发布命令执行快照保存外，redis的serverCron也会按照配置的参数执行后台dump，另外 slave建立连接时，master也会执行一个后台dump，然后才发送数据给slave（这在主从复制一节中介绍）。
    
    </summary>
    
      <category term="redis" scheme="http://www.petermao.com/categories/redis/"/>
    
    
  </entry>
  
  <entry>
    <title>redis源代码分析16–阻塞式命令</title>
    <link href="http://www.petermao.com/redis/102/"/>
    <id>http://www.petermao.com/redis/102/</id>
    <published>2011-05-01T02:43:28.000Z</published>
    <updated>2017-02-14T02:02:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>redis现在只支持对list的阻塞式操作，相关的两个命令是brpop和blpop。</p>
<p>这两个命令在list中有元素时，跟普通的pop没有区别，弹出list的一个元素，然后返回。但在list没有元素时，会为redisClient设置REDIS_BLOCKED标志，然后client阻塞（设置REDIS_BLOCKED标志的redisClient会一直阻塞，参考命令处理章节），一直到新元素加入时（push操作的处理函数pushGenericCommand），才会返回。</p>
<p>这两个命令设置的处理函数brpopCommand和blpopCommand都会调用blockingPopGenericCommand。该函数在检查list中有元素后，会调用非阻塞的popGenericCommand来弹出一个元素，否则调用blockForKeys来处理阻塞的情况。<a id="more"></a></p>
<pre>
/* Blocking RPOP/LPOP */
static void blockingPopGenericCommand(redisClient *c, int where) {
    robj *o;
    long long lltimeout;
    time_t timeout;
    int j;

    /* Make sure timeout is an integer value */
    if (getLongLongFromObjectOrReply(c,c->argv[c->argc-1],&lltimeout,
            "timeout is not an integer") != REDIS_OK) return;

    /* Make sure the timeout is not negative */
    if (lltimeout < 0) {
        addReplySds(c,sdsnew("-ERR timeout is negative\r\n"));
        return;
    }

    for (j = 1; j < c->argc-1; j++) {
        o = lookupKeyWrite(c->db,c->argv[j]);
        if (o != NULL) {
            if (o->type != REDIS_LIST) {
                addReply(c,shared.wrongtypeerr);
                return;
            } else {
                list *list = o->ptr;
                if (listLength(list) != 0) {
                    /* If the list contains elements fall back to the usual
                     * non-blocking POP operation */
                    robj *argv[2], **orig_argv;
                    int orig_argc;

                    /* We need to alter the command arguments before to call
                     * popGenericCommand() as the command takes a single key. */
                    orig_argv = c->argv;
                    orig_argc = c->argc;
                    argv[1] = c->argv[j];
                    c->argv = argv;
                    c->argc = 2;

                    /* Also the return value is different, we need to output
                     * the multi bulk reply header and the key name. The
                     * "real" command will add the last element (the value)
                     * for us. If this souds like an hack to you it's just
                     * because it is... */
                    addReplySds(c,sdsnew("*2\r\n"));
                    addReplyBulk(c,argv[1]);
                    popGenericCommand(c,where);

                    /* Fix the client structure with the original stuff */
                    c->argv = orig_argv;
                    c->argc = orig_argc;
                    return;
                }
            }
        }
    }

    /* If we are inside a MULTI/EXEC and the list is empty the only thing
     * we can do is treating it as a timeout (even with timeout 0). */
    if (c->flags & REDIS_MULTI) {
        addReply(c,shared.nullmultibulk);
        return;
    }

    /* If the list is empty or the key does not exists we must block */
    timeout = lltimeout;
    if (timeout > 0) timeout += time(NULL);
    blockForKeys(c,c->argv+1,c->argc-2,timeout);
}
</pre>
blockForKeys会在db->blockingkeys记下client和等待的key的对应关系，然后给client设置REDIS_BLOCKED标志，这样client就一直阻塞了。
<pre>
static void blockForKeys(redisClient *c, robj **keys, int numkeys, time_t timeout) {
    dictEntry *de;
    list *l;
    int j;
    ---
    if (c->fd < 0) return;

    c->blockingkeys = zmalloc(sizeof(robj*)*numkeys);
    c->blockingkeysnum = numkeys;
    c->blockingto = timeout;
    for (j = 0; j < numkeys; j++) {
        /* Add the key in the client structure, to map clients -> keys */
        c->blockingkeys[j] = keys[j];
        incrRefCount(keys[j]);

        /* And in the other "side", to map keys -> clients */
        de = dictFind(c->db->blockingkeys,keys[j]);
        if (de == NULL) {
            int retval;

            /* For every key we take a list of clients blocked for it */
            l = listCreate();
            retval = dictAdd(c->db->blockingkeys,keys[j],l);
            incrRefCount(keys[j]);
            assert(retval == DICT_OK);
        } else {
            l = dictGetEntryVal(de);
        }
        listAddNodeTail(l,c);
    }
    /* Mark the client as a blocked client */
    c->flags |= REDIS_BLOCKED;
    server.blpop_blocked_clients++;
}
</pre>
等待的client会一直阻塞，直到有push操作，此时会调用unblockClientWaitingData来解除client的阻塞。
<pre>
/* Unblock a client that's waiting in a blocking operation such as BLPOP */
// 减少对所阻塞对象的引用
static void unblockClientWaitingData(redisClient *c) {
    dictEntry *de;
    list *l;
    int j;

    assert(c->blockingkeys != NULL);
    /* The client may wait for multiple keys, so unblock it for every key. */
    for (j = 0; j < c->blockingkeysnum; j++) {
        /* Remove this client from the list of clients waiting for this key. */
        de = dictFind(c->db->blockingkeys,c->blockingkeys[j]);
        assert(de != NULL);
        l = dictGetEntryVal(de);
        listDelNode(l,listSearchKey(l,c));
        /* If the list is empty we need to remove it to avoid wasting memory */
        if (listLength(l) == 0)
            dictDelete(c->db->blockingkeys,c->blockingkeys[j]);
        decrRefCount(c->blockingkeys[j]);
    }
    /* Cleanup the client structure */
    zfree(c->blockingkeys);
    c->blockingkeys = NULL;
    c->flags &= (~REDIS_BLOCKED);
    server.blpop_blocked_clients--;
    /* We want to process data if there is some command waiting
     * in the input buffer. Note that this is safe even if
     * unblockClientWaitingData() gets called from freeClient() because
     * freeClient() will be smart enough to call this function
     * *after* c->querybuf was set to NULL. */
    if (c->querybuf && sdslen(c->querybuf) > 0) processInputBuffer(c);
}
</pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;redis现在只支持对list的阻塞式操作，相关的两个命令是brpop和blpop。&lt;/p&gt;
&lt;p&gt;这两个命令在list中有元素时，跟普通的pop没有区别，弹出list的一个元素，然后返回。但在list没有元素时，会为redisClient设置REDIS_BLOCKED标志，然后client阻塞（设置REDIS_BLOCKED标志的redisClient会一直阻塞，参考命令处理章节），一直到新元素加入时（push操作的处理函数pushGenericCommand），才会返回。&lt;/p&gt;
&lt;p&gt;这两个命令设置的处理函数brpopCommand和blpopCommand都会调用blockingPopGenericCommand。该函数在检查list中有元素后，会调用非阻塞的popGenericCommand来弹出一个元素，否则调用blockForKeys来处理阻塞的情况。
    
    </summary>
    
      <category term="redis" scheme="http://www.petermao.com/categories/redis/"/>
    
    
  </entry>
  
  <entry>
    <title>redis源代码分析15–val加载机制</title>
    <link href="http://www.petermao.com/redis/100/"/>
    <id>http://www.petermao.com/redis/100/</id>
    <published>2011-04-30T20:30:43.000Z</published>
    <updated>2017-02-14T02:02:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>这一节主要介绍下val的加载。</p>
<p>对于某些命令，比如get somekey，当运行到processCommand时可能key对应的val不在内存中。在运行命令绑定的处理函数之前，redis会提前加载其val。</p>
<p>在 processCommand中，在vm开启并启用多线程时，会调用 blockClientOnSwappedKeys来加载可能已swap的val，如果blockClientOnSwappedKeys返回0，说明有 swap的val没被加载，则返回不调用call了（此时client会设置 REDIS_IO_WAIT标志，并已放到等待列表中）。代码如下：<a id="more"></a></p>
<p><pre></pre></p>
<h2 id="static-int-processCommand-redisClient-c"><a href="#static-int-processCommand-redisClient-c" class="headerlink" title="static int processCommand(redisClient *c) {"></a>static int processCommand(redisClient *c) {</h2><pre><code>if (server.vm_enabled &amp;&amp; server.vm_max_threads &gt; 0 &amp;&amp;
       blockClientOnSwappedKeys(c,cmd)) return 1;
   call(c,cmd);
 ---
</code></pre><p>}<br><br>在blockClientOnSwappedKeys函数中，如果命令设置了预加载函数，比如zunionstore和zinterstore就设置了预加载函数 zunionInterBlockClientOnSwappedKeys，则使用设置的预加载函数加载swap的val，否则使用 waitForMultipleSwappedKeys加载swap的val，不过查看 zunionInterBlockClientOnSwappedKeys和waitForMultipleSwappedKeys的实现就可以发现， 这些函数最终都调用waitForSwappedKey。在预加载函数返回后，若client的io_keys链表非空（io_keys是该client 不在内存中的val的链表），则设置client的REDIS_IO_WAIT标志，取消client的read 事件（在这之前，client已放到对应key的阻塞队列中了）。</p>
<p><pre><br>static int blockClientOnSwappedKeys(redisClient <em>c, struct redisCommand </em>cmd) {<br>    if (cmd-&gt;vm_preload_proc != NULL) {<br>        cmd-&gt;vm_preload_proc(c,cmd,c-&gt;argc,c-&gt;argv);<br>    } else {<br>        waitForMultipleSwappedKeys(c,cmd,c-&gt;argc,c-&gt;argv);<br>    }</pre></p>
<pre><code>/* If the client was blocked for at least one key, mark it as blocked. */
if (listLength(c-&gt;io_keys)) {
    c-&gt;flags |= REDIS_IO_WAIT;
    aeDeleteFileEvent(server.el,c-&gt;fd,AE_READABLE);
    server.vm_blocked_clients++;
    return 1;
} else {
    return 0;
}
</code></pre><p>}<br><br>我们看看waitForMultipleSwappedKeys的实现。waitForMultipleSwappedKeys会根据命令字表中设置的预加载参数，加载需要加载的val。</p>
<p><pre><br>static void waitForMultipleSwappedKeys(redisClient <em>c, struct redisCommand </em>cmd, int argc, robj **argv) {<br>    int j, last;<br>    if (cmd-&gt;vm_firstkey == 0) return;<br>    last = cmd-&gt;vm_lastkey;<br>    if (last &lt; 0) last = argc+last;<br>    for (j = cmd-&gt;vm_firstkey; j &lt;= last; j += cmd-&gt;vm_keystep) {<br>        redisAssert(j &lt; argc);<br>        waitForSwappedKey(c,argv[j]);<br>    }<br>}<br></pre><br>比如我们查看get命令字的设置。后面的1,1,1就是表示加载的val在argv中的位置，每个get命令最多需要预加载1个val。</p>
<p><pre><br>{“get”,getCommand,2,REDIS_CMD_INLINE,NULL,1,1,1},<br></pre><br>waitForSwappedKey 涉及到vm的多线程，建议先粗略理解下，并在阅读vm章节后再返回此处阅读。该函数所做的主要工作就是将(c, key) 加到c-&gt;db-&gt;io_keys中，而db其实指向全局server的db，然后创建一个job，插入到工作线程中，让工作线程完成val 的加载。</p>
<p><pre><br>static int waitForSwappedKey(redisClient <em>c, robj </em>key) {<br>    struct dictEntry <em>de;<br>    robj </em>o;<br>    list *l;</pre></p>
<pre><code>/* If the key does not exist or is already in RAM we don&apos;t need to
 * block the client at all. */
de = dictFind(c-&gt;db-&gt;dict,key);
if (de == NULL) return 0;
o = dictGetEntryKey(de);
if (o-&gt;storage == REDIS_VM_MEMORY) {
    return 0;
} else if (o-&gt;storage == REDIS_VM_SWAPPING) {
    /* We were swapping the key, undo it! */
    vmCancelThreadedIOJob(o);
    return 0;
}

/* OK: the key is either swapped, or being loaded just now. */

/* Add the key to the list of keys this client is waiting for.
 * This maps clients to keys they are waiting for. */
listAddNodeTail(c-&gt;io_keys,key);
incrRefCount(key);

/* Add the client to the swapped keys =&gt; clients waiting map. */
de = dictFind(c-&gt;db-&gt;io_keys,key);
if (de == NULL) {
    int retval;

    /* For every key we take a list of clients blocked for it */
    l = listCreate();
    retval = dictAdd(c-&gt;db-&gt;io_keys,key,l);
    incrRefCount(key);
    assert(retval == DICT_OK);
} else {
    l = dictGetEntryVal(de);
}
listAddNodeTail(l,c);

/* Are we already loading the key from disk? If not create a job */
if (o-&gt;storage == REDIS_VM_SWAPPED) {
    iojob *j;

    o-&gt;storage = REDIS_VM_LOADING;
    j = zmalloc(sizeof(*j));
    j-&gt;type = REDIS_IOJOB_LOAD;
    j-&gt;db = c-&gt;db;
    j-&gt;key = o;
    j-&gt;key-&gt;vtype = o-&gt;vtype;
    j-&gt;page = o-&gt;vm.page;
    j-&gt;val = NULL;
    j-&gt;canceled = 0;
    j-&gt;thread = (pthread_t) -1;
    lockThreadedIO();
    queueIOJob(j);
    unlockThreadedIO();
}
return 1;
</code></pre><p>}<br><br>插入工作线程的job在运行完后，会调用 vmThreadedIOCompletedJob，在该函数中会调用handleClientsBlockedOnSwappedKey处理阻塞的 client，而handleClientsBlockedOnSwappedKey所做的主要工作就是将所有val已加载的client放到 server.io_ready_clients中，此时client已ready好了，但还没有加入read事件循环（因为之前因为等待val已删除其 read事件）。</p>
<p><pre><br>static void handleClientsBlockedOnSwappedKey(redisDb <em>db, robj </em>key) {<br>    struct dictEntry <em>de;<br>    list </em>l;<br>    listNode *ln;<br>    int len;</pre></p>
<pre><code>de = dictFind(db-&gt;io_keys,key);
if (!de) return;

l = dictGetEntryVal(de);
len = listLength(l);
/* Note: we can&apos;t use something like while(listLength(l)) as the list
 * can be freed by the calling function when we remove the last element. */
while (len--) {
    ln = listFirst(l);
    redisClient *c = ln-&gt;value;

    if (dontWaitForSwappedKey(c,key)) {
        /* Put the client in the list of clients ready to go as we
         * loaded all the keys about it. */
        listAddNodeTail(server.io_ready_clients,c);
    }
}
</code></pre><p>}<br><br>最后还剩下一个问题，那就是处于server.io_ready_clients的clint会在什么时候增加read事件，从而继续让其接收客户端的输入了。这个工作在beforeSleep函数中完成（前面的事件循环中有详细介绍）。beforeSleep会为server.io_ready_clients中的client增加read事件，调用processInputBuffer处理其输入。</p>
<p>另外注意，如果client需要的val在检查时都在内存中，但当执行命令处理函数时，该val被swap出去了，则只能使用vmLoadObject直接加载了（阻塞方式）。对此种情况，redis的解释是In practical terms this should onlyhappen with SORT BY command or if there is a bug in this function（参考blockClientOnSwappedKeys前的注释）。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这一节主要介绍下val的加载。&lt;/p&gt;
&lt;p&gt;对于某些命令，比如get somekey，当运行到processCommand时可能key对应的val不在内存中。在运行命令绑定的处理函数之前，redis会提前加载其val。&lt;/p&gt;
&lt;p&gt;在 processCommand中，在vm开启并启用多线程时，会调用 blockClientOnSwappedKeys来加载可能已swap的val，如果blockClientOnSwappedKeys返回0，说明有 swap的val没被加载，则返回不调用call了（此时client会设置 REDIS_IO_WAIT标志，并已放到等待列表中）。代码如下：
    
    </summary>
    
      <category term="redis" scheme="http://www.petermao.com/categories/redis/"/>
    
    
  </entry>
  
  <entry>
    <title>redis源代码分析14–命令处理的一般过程</title>
    <link href="http://www.petermao.com/redis/98/"/>
    <id>http://www.petermao.com/redis/98/</id>
    <published>2011-04-30T20:28:16.000Z</published>
    <updated>2017-02-14T02:02:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>这个部分我们介绍下命令处理的一般过程。<br>在createClient时，为client的read事件设置了readQueryFromClient函数。我们来看看怎么处理client的命令的。<br>readQueryFromClient使用read一次读入REDIS_IOBUF_LEN字节，并保存在client中的querybuf参数中，然后调用processInputBuffer继续处理。<a id="more"></a></p>
<p><pre><br>static void readQueryFromClient(aeEventLoop <em>el, int fd, void </em>privdata, int mask){</pre></p>
<h2 id="redisClient-c-redisClient-privdata"><a href="#redisClient-c-redisClient-privdata" class="headerlink" title="   redisClient c =(redisClient)privdata;"></a>   redisClient <em>c =(redisClient</em>)privdata;</h2><h2 id="nread-read-fd-buf-REDIS-IOBUF-LEN"><a href="#nread-read-fd-buf-REDIS-IOBUF-LEN" class="headerlink" title="   nread = read(fd, buf, REDIS_IOBUF_LEN);"></a>   nread = read(fd, buf, REDIS_IOBUF_LEN);</h2><p>   if(nread){<br>       c-&gt;querybuf = sdscatlen(c-&gt;querybuf, buf, nread);<br>       c-&gt;lastinteraction = time(NULL);<br>   } else {<br>       return;<br>   }<br>   processInputBuffer(c);<br>}<br><br>processInputBuffer只处理不在REDIS_BLOCKED 和REDIS_IO_WAIT状态的client，也就是已ready好的client。另外如果c-&gt;bulklen ==-1（对于一般命令，c-&gt;bulklen都为-1，对于用multibulk协议传输的命令，下一个函数有更详细的介绍），则按行解析querybuf，并将解析到的参数保存在argv中，然后调用processCommand进行下一步处理，并且如果processCommand返回非0，会继续处理client输入。</p>
<p><pre><br>static void processInputBuffer(redisClient *c) {</pre></p>
<h2 id="again"><a href="#again" class="headerlink" title="again:"></a>again:</h2><pre><code>if (c-&gt;flags &amp; REDIS_BLOCKED || c-&gt;flags &amp; REDIS_IO_WAIT) return;
if (c-&gt;bulklen == -1) {
   --
    if (p) {
        ---
        if (c-&gt;argc) {
           ---
            if (processCommand(c) &amp;&amp; sdslen(c-&gt;querybuf)) goto again;
        }
        --
    }
} else {
    --
    int qbl = sdslen(c-&gt;querybuf);
    if (processCommand(c) &amp;&amp; sdslen(c-&gt;querybuf)) goto again;
        return;
}
</code></pre><p>}<br><br>processCommand这段代码对multi-bulk 协议的解析写得真不敢恭维，转来转去的，真没劲。参看代码中的解释。解析完multibulk后，如果输入的命令是quit，则表示客户端退出了，释放其连接，返回0，表示不用继续处理了。接着使用 lookupCommand查看命令在cmdTable中对应的命令项，然后又是multbulk，接着检查安全认证情况，接着检查内存使用（前面内存章节中有介绍），接着查看 pubsub_channels、pubsub_patterns长度是否为0，若不为0，则表示处于订阅模式下（后文介绍），只允许命令 subscribeCommand、unsubscribeCommand、psubscribeCommand、 punsubscribeCommand。接着如果client处于事务模式下，则在命令不是execCommand、discardCommand的情况下将命令排队（事务处理后文也有介绍）。接着看看是否需要预先加载key，最后终于来到call函数中调用命令了。</p>
<p><pre><br>static int processCommand(redisClient *c) {</pre></p>
<pre><code>struct redisCommand *cmd;

 ---

 // 第一个字符是 * 表示后面是multi-bulk协议格式

// 解析得到后面的data 项数
if (c-&gt;multibulk == 0 &amp;&amp; c-&gt;argc == 1 &amp;&amp; ((char*)(c-&gt;argv[0]-&gt;ptr))[0] == &apos;*&apos;) {
    c-&gt;multibulk = atoi(((char*)c-&gt;argv[0]-&gt;ptr)+1);
    if (c-&gt;multibulk &lt;= 0) {
        resetClient(c);
        return 1;
    } else {
        decrRefCount(c-&gt;argv[c-&gt;argc-1]);
        c-&gt;argc--;
        return 1;
    }
} else if (c-&gt;multibulk) {
    // 解析时对于普通的命令: c-&gt;bulklen始终 = -1,
    //前面已获得 c-&gt;multibulk值, c-&gt;bulklen一开始为-1，随后在 if (c-&gt;bulklen == -1) 中置为需要读取的字符个数，然后返回到processInputBuffer的else中处理得到输入的参数，然后再到这儿时就会进入 if (c-&gt;bulklen == -1) 的else中，将参数保存到mbargv中，这样一直到 c-&gt;multibulk为0，才解析完multibulk协议，进行下一步处理。
    if (c-&gt;bulklen == -1) {
        if (((char*)c-&gt;argv[0]-&gt;ptr)[0] != &apos;$&apos;) {
            addReplySds(c,sdsnew(&quot;-ERR multi bulk protocol error\r\n&quot;));
            resetClient(c);
            return 1;
        } else {
            int bulklen = atoi(((char*)c-&gt;argv[0]-&gt;ptr)+1);
            decrRefCount(c-&gt;argv[0]);
            if (bulklen &lt; 0 || bulklen &gt; 1024*1024*1024) {
                c-&gt;argc--;
                addReplySds(c,sdsnew(&quot;-ERR invalid bulk write count\r\n&quot;));
                resetClient(c);
                return 1;
            }
            c-&gt;argc--;
            c-&gt;bulklen = bulklen+2; /* add two bytes for CR+LF */
            return 1;
        }
    } else {
        c-&gt;mbargv = zrealloc(c-&gt;mbargv,(sizeof(robj*))*(c-&gt;mbargc+1));
        c-&gt;mbargv[c-&gt;mbargc] = c-&gt;argv[0];
        c-&gt;mbargc++;
        c-&gt;argc--;
        c-&gt;multibulk--;
        if (c-&gt;multibulk == 0) {
            robj **auxargv;
            int auxargc;

            /* Here we need to swap the multi-bulk argc/argv with the
             * normal argc/argv of the client structure. */
            auxargv = c-&gt;argv;
            c-&gt;argv = c-&gt;mbargv;
            c-&gt;mbargv = auxargv;

            auxargc = c-&gt;argc;
            c-&gt;argc = c-&gt;mbargc;
            c-&gt;mbargc = auxargc;

            /* We need to set bulklen to something different than -1
             * in order for the code below to process the command without
             * to try to read the last argument of a bulk command as
             * a special argument. */
            c-&gt;bulklen = 0;
            /* continue below and process the command */
        } else {
            c-&gt;bulklen = -1;
            return 1;
        }
    }
}
/* -- end of multi bulk commands processing -- */

---
if (!strcasecmp(c-&gt;argv[0]-&gt;ptr,&quot;quit&quot;)) {
    freeClient(c);
    return 0;
}
---
cmd = lookupCommand(c-&gt;argv[0]-&gt;ptr);
if (!cmd) {
    addReplySds(c,
        sdscatprintf(sdsempty(), &quot;-ERR unknown command &apos;%s&apos;\r\n&quot;,
            (char*)c-&gt;argv[0]-&gt;ptr));
    resetClient(c);
    return 1;
} else if ((cmd-&gt;arity &gt; 0 &amp;&amp; cmd-&gt;arity != c-&gt;argc) ||
           (c-&gt;argc &lt; -cmd-&gt;arity)) {
    addReplySds(c,
        sdscatprintf(sdsempty(),
            &quot;-ERR wrong number of arguments for &apos;%s&apos; command\r\n&quot;,
            cmd-&gt;name));
    resetClient(c);
    return 1;
} else if (cmd-&gt;flags &amp; REDIS_CMD_BULK &amp;&amp; c-&gt;bulklen == -1) {
    /* This is a bulk command, we have to read the last argument yet. */
    int bulklen = atoi(c-&gt;argv[c-&gt;argc-1]-&gt;ptr);

    decrRefCount(c-&gt;argv[c-&gt;argc-1]);
    if (bulklen &lt; 0 || bulklen &gt; 1024*1024*1024) {
        c-&gt;argc--;
        addReplySds(c,sdsnew(&quot;-ERR invalid bulk write count\r\n&quot;));
        resetClient(c);
        return 1;
    }
    c-&gt;argc--;
    c-&gt;bulklen = bulklen+2; /* add two bytes for CR+LF */
   ---
    if ((signed)sdslen(c-&gt;querybuf) &gt;= c-&gt;bulklen) {
        c-&gt;argv[c-&gt;argc] = createStringObject(c-&gt;querybuf,c-&gt;bulklen-2);
        c-&gt;argc++;
        c-&gt;querybuf = sdsrange(c-&gt;querybuf,c-&gt;bulklen,-1);
    } else {
        /* Otherwise return... there is to read the last argument
         * from the socket. */
        return 1;
    }
}
/* Let&apos;s try to encode the bulk object to save space. */
if (cmd-&gt;flags &amp; REDIS_CMD_BULK)
    c-&gt;argv[c-&gt;argc-1] = tryObjectEncoding(c-&gt;argv[c-&gt;argc-1]);

/* Check if the user is authenticated */
if (server.requirepass &amp;&amp; !c-&gt;authenticated &amp;&amp; cmd-&gt;proc != authCommand) {
    addReplySds(c,sdsnew(&quot;-ERR operation not permitted\r\n&quot;));
    resetClient(c);
    return 1;

}
if (server.maxmemory) freeMemoryIfNeeded();
if (server.maxmemory &amp;&amp; (cmd-&gt;flags &amp; REDIS_CMD_DENYOOM) &amp;&amp;
    zmalloc_used_memory() &gt; server.maxmemory)
{
    addReplySds(c,sdsnew(&quot;-ERR command not allowed when used memory &gt; &apos;maxmemory&apos;\r\n&quot;));
    resetClient(c);
    return 1;
}

/* Only allow SUBSCRIBE and UNSUBSCRIBE in the context of Pub/Sub */
if ((dictSize(c-&gt;pubsub_channels) &gt; 0 || listLength(c-&gt;pubsub_patterns) &gt; 0)
    &amp;&amp;
    cmd-&gt;proc != subscribeCommand &amp;&amp; cmd-&gt;proc != unsubscribeCommand &amp;&amp;
    cmd-&gt;proc != psubscribeCommand &amp;&amp; cmd-&gt;proc != punsubscribeCommand) {
    addReplySds(c,sdsnew(&quot;-ERR only (P)SUBSCRIBE / (P)UNSUBSCRIBE / QUIT allowed in this context\r\n&quot;));
    resetClient(c);
    return 1;
}

/* Exec the command */
if (c-&gt;flags &amp; REDIS_MULTI &amp;&amp; cmd-&gt;proc != execCommand &amp;&amp; cmd-&gt;proc != discardCommand) {
    queueMultiCommand(c,cmd);
    addReply(c,shared.queued);
} else {
    if (server.vm_enabled &amp;&amp; server.vm_max_threads &gt; 0 &amp;&amp;
        blockClientOnSwappedKeys(c,cmd)) return 1;
    call(c,cmd);
}

/* Prepare the client for the next command */
resetClient(c);
return 1;
</code></pre><p>}<br><br>call函数首先调用命令字绑定的处理函数，返回时检查是否修改数据，若有修改，则在aof启用的情况下，写aof log，并在数据改变或者强制复制的情况下向slaves复制，最后向monitors发送当前命令及参数。</p>
<p><pre><br>/<em> Call() is the core of Redis execution of a command </em>/<br>static void call(redisClient <em>c, struct redisCommand </em>cmd) {<br>    long long dirty;</pre></p>
<pre><code>dirty = server.dirty;
cmd-&gt;proc(c);
dirty = server.dirty-dirty;

if (server.appendonly &amp;&amp; dirty)
    feedAppendOnlyFile(cmd,c-&gt;db-&gt;id,c-&gt;argv,c-&gt;argc);
if ((dirty || cmd-&gt;flags &amp; REDIS_CMD_FORCE_REPLICATION) &amp;&amp;
    listLength(server.slaves))
    replicationFeedSlaves(server.slaves,c-&gt;db-&gt;id,c-&gt;argv,c-&gt;argc);
if (listLength(server.monitors))
    replicationFeedMonitors(server.monitors,c-&gt;db-&gt;id,c-&gt;argv,c-&gt;argc);
server.stat_numcommands++;
</code></pre><p>}<br><br>最后介绍下命令表，定义如下：</p>
<p><pre><br>struct redisCommand {<br>    char <em>name;<br>    redisCommandProc </em>proc;<br>    int arity;<br>    int flags;<br>    /* Use a function to determine which keys need to be loaded</pre></p>
<pre><code> * in the background prior to executing this command. Takes precedence
 * over vm_firstkey and others, ignored when NULL */
redisVmPreloadProc *vm_preload_proc;
/* What keys should be loaded in background when calling this command? */
int vm_firstkey; /* The first argument that&apos;s a key (0 = no keys) */
int vm_lastkey;  /* THe last argument that&apos;s a key */
int vm_keystep;  /* The step between first and last key */
</code></pre><p>};<br><br>对于每一个命令字，都有一个name和一个处理函数，对于某些key，在启用vm的情况下，需要使用vm_preload_proc预先加载某些key。下一节我们介绍下key的预先加载。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这个部分我们介绍下命令处理的一般过程。&lt;br&gt;在createClient时，为client的read事件设置了readQueryFromClient函数。我们来看看怎么处理client的命令的。&lt;br&gt;readQueryFromClient使用read一次读入REDIS_IOBUF_LEN字节，并保存在client中的querybuf参数中，然后调用processInputBuffer继续处理。
    
    </summary>
    
      <category term="redis" scheme="http://www.petermao.com/categories/redis/"/>
    
    
  </entry>
  
  <entry>
    <title>redis源代码分析13–client连接（下）</title>
    <link href="http://www.petermao.com/redis/96/"/>
    <id>http://www.petermao.com/redis/96/</id>
    <published>2011-04-30T20:25:37.000Z</published>
    <updated>2017-02-14T02:02:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>这一节我们介绍下client连接的几个标志。</p>
<p>client的flags的取值有如下几种：</p>
<p><pre></pre></p>
<p>#define REDIS_SLAVE 1      /<em> This client is a slave server </em>/</p>
<p>#define REDIS_MASTER 2     /<em> This client is a master server </em>/</p>
<p>#define REDIS_MONITOR 4    /<em> This client is a slave monitor, see MONITOR </em>/</p>
<p>#define REDIS_MULTI 8      /<em> This client is in a MULTI context </em>/</p>
<p>#define REDIS_BLOCKED 16   /<em> The client is waiting in a blocking operation </em>/</p>
<p>#define REDIS_IO_WAIT 32   /<em> The client is waiting for Virtual Memory I/O </em>/<br><br>redis支持主从复制、监控特性，对这些server的连接状态也是保存在当前server的redisClient结构中， 并在redisClient的flags标志中设置REDIS_SLAVE 、REDIS_MASTER、 REDIS_MONITOR参数。我们在后续的章节中详细分析redis的主从复制、监控等特性。</p>
<p>一般的client仅会设置REDIS_MULTI、REDIS_BLOCKED、REDIS_IO_WAIT中的1个或多个。REDIS_MULTI跟redis的事务支持相关，我们后续介绍。REDIS_BLOCKED标志跟redis支持的list阻塞式pop（BLPOP、BRPOP）有关，也就是当list为空的时候，会阻塞client，一直到有元素加入list，此时再pop。REDIS_IO_WAIT跟命令字有关，对于某些命令，如果启用vm的话，需要提前加载其key。我们在命令处理章节中分析。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这一节我们介绍下client连接的几个标志。&lt;/p&gt;
&lt;p&gt;client的flags的取值有如下几种：&lt;/p&gt;
&lt;p&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;#define REDIS_SLAVE 1      /&lt;em&gt; This client is a slave ser
    
    </summary>
    
      <category term="redis" scheme="http://www.petermao.com/categories/redis/"/>
    
    
  </entry>
  
</feed>
